# Discrete Mathematics and Application

# Ch1 Logic & Proofs

## 1.1 Propositional Logic

### 1. Propositions

<u>A proposition is a **declarative sentence** (that is, a sentence that declares a fact) that is either `true` or `false`, but not both.</u>

- **Paradox (æ‚–è®º)** ä¸å±äºå‘½é¢˜ï¼ˆe.g. *This statement is false.* or *I'm lying.*ï¼‰

**Propositional variable / Sentential variables (å‘½é¢˜å˜é‡)**ï¼šSmall letters such as $p,q,r,s,\dots$ used to present propositions.

**Propositional logic / Propositional calculus (å‘½é¢˜é€»è¾‘)**ï¼šThe area of logic that deals with propositions.

**Truth value(çœŸå€¼)**ï¼šT (true proposition), or F (false proposition)

We call a series of propositions **==consistent== (ä¸€è‡´çš„)** if they can possibly be satisfied at the same time.

### 2. Connectives

#### Logical Operators

**Logical operator** or **Logical Connective**: be used to form **compound propositions** from existing propositions.

| Connectives                           | Expression |               Note               |
| :------------------------------------ | :--------: | :------------------------------: |
| negation (NOT)                        |    $Â¬p$    | $~p, -p, p', Np, \text{and } !p$ |
| å’Œå– conjunction (AND)                |   $pâˆ§q$    |          "but" = "and"           |
| æå– disjunction (OR)                 |   $pâˆ¨q$    |         an inclusive or          |
| äº¦æˆ– Exclusive Or (XOR)               |   $pâŠ•q$    |         an exclusive or          |
| æ¡ä»¶ Conditional (IF-THEN)            |   $pâ†’q$    |                                  |
| åŒæ¡ä»¶ Biconditional (IF AND ONLY IF) |   $pâ†”q$    |           å‚è§ä¸‹èŠ‚ä»‹ç»           |

- è‹±è¯­ä¸­çš„å•è¯ or æ—¢å¯ä»¥è¡¨ç¤º **inclusive or** ä¹Ÿå¯ä»¥è¡¨ç¤º **exclusive or**ï¼ˆe.g. *George was born in 1956 or 1957.*ï¼‰ï¼Œå–å†³äºå…·ä½“è¯­å¢ƒã€‚

é€»è¾‘è¿ç®—ç¬¦çš„**ä¼˜å…ˆçº§(precedence)** å¦‚ä¸‹ï¼š

|  Â¬   | âˆ§ |âˆ¨ | â†’ | â†” |
| :--: | :--: | :--: | :--: | :--: |
|  1   |   2   |   3   |   4   |   5   |

####  Conditional Statements

==**Implication** or **Conditional statement**== ï¼š$pâ†’q$ is false when $p$ is true and $q$ is false, and true otherwise.

- **p :** **å‡è®¾(hypothesis / antecedent / premise)**
- **q :** **ç»“è®º(conclusion / consequence)**


å¯¹äºæ¨æ–­ pâ†’qå¯å®šä¹‰ä»¥ä¸‹æ¡ä»¶è¯­å¥ï¼š

- **Converse (é€†å‘½é¢˜)**ï¼š$qâ†’p$
- **Inverse (å¦å‘½é¢˜)**ï¼š$Â¬pâ†’Â¬q$
- **Contrapositive (é€†å¦å‘½é¢˜)**ï¼š$Â¬qâ†’Â¬p$


When two compound propositions always have the same truth values, regardless of the truth values of its propositional variables, we call them **==equivalent==ï¼ˆç­‰ä»·çš„ï¼‰**.

* The ***contrapositive*** has the **same** truth values as the original implication.

* The ***converse*** and the ***inverse*** of a conditional statement are also **equivalent**.

**==Biconditional statement (åŒæ¡ä»¶è¯­å¥)==**ï¼šThe biconditional statement pâ†”q is the propostion â€œp if and only if q.â€ 

### 3. Truth Table

è¦å­¦ä¼šç”»**çœŸå€¼è¡¨(truth table)**ã€‚

- nä¸ªä¸åŒçš„å¸ƒå°”å˜é‡æ‰€ç”»çš„çœŸå€¼è¡¨åº”æœ‰ $2^{n}$ è¡Œã€‚

### 4. Logic and Bit Operatons

**Bit**: a symbol with two possible values , namely, 0 and 1.

**Boolean variable**: one whose value is either true or false.

## 1.2 Applications of Propositional Logic

* Translating English to Propositional Logic

* System Specifications
  * System specifications should be **consistent**.

* Logic Puzzles

## 1.3 Propositional Equivalences

### 1. Introduction

* A **tautology (æ°¸çœŸ)** is a proposition which is always true.  Example: $p âˆ¨Â¬p $
* A **contradiction (æ°¸å‡)** is a proposition which is always false.  Example: $p âˆ§Â¬p $
* A **contingency (å¯èƒ½å¼)** is a proposition which is neither a tautology nor a  contradiction, such as $ p$

**Propositional Satisfiability**

* A compound proposition is **==satisfiable==** if there is an assignment of truth values to its  variables that makes it true. 
* A compound proposition is **==unsatisfiable==** when it is false for all assignments of truth  values to its variables.

**Equivalent**

* The propositions $p$ and $q$ are called ==**logically equivalentï¼ˆé€»è¾‘ç­‰å€¼ï¼‰**== if $p â†” q$ is a  tautology.

* Notation: $p â‡” q$ or $p â‰¡ q$

**Other logical operators**

* <u>Sheffer stroke</u> |:  $p|q â‰¡ Â¬(p âˆ§ q) $ NAND 
* <u>Peirce arrow</u> â†“:  $p â†“ q â‰¡ Â¬(p âˆ¨ q) $ NOR

### 2. Logical Laws

- å¯ä»¥ç”¨çœŸå€¼è¡¨æ¥è¯æ˜ä¸€äº›åŸºæœ¬çš„é€»è¾‘å®šå¾‹ï¼šå¯¹äºæ¶‰åŠåˆ°$n$ä¸ªå˜é‡çš„ä¸¤ä¸ªå‘½é¢˜ï¼Œç”»å‡º $2^n$ ç§å¯èƒ½çš„å˜é‡å–å€¼ä¸‹çš„çœŸå€¼è¡¨ï¼Œè‹¥ä¸¤ä¸ªå‘½é¢˜çš„å€¼éƒ½ç›¸åŒï¼Œåˆ™è¯´æ˜è¿™ä¸¤ä¸ªå‘½é¢˜æ˜¯é€»è¾‘ç­‰å€¼çš„ã€‚

  | Name                           |                     Expression                     | Note                   |
  | :----------------------------- | :------------------------------------------------: | :--------------------- |
  | ç»Ÿä¸€å¾‹ Identity Laws           |               $pâˆ§T â‰¡ p$   $pâˆ¨F â‰¡ p$                |                        |
  | é›¶ä¸€å¾‹ Domination Laws         |               $pâˆ¨T â‰¡ T$   $pâˆ§F â‰¡ F$                |                        |
  | å¹‚ç­‰å¾‹ Idempotent Laws         |               $pâˆ§p â‰¡ p$   $pâˆ¨p â‰¡ p$                |                        |
  | å¯¹åˆå¾‹ Double Negation Law     |                     $Â¬Â¬p â‰¡ p$                      |                        |
  | äº¤æ¢å¾‹ Commutative Laws        |             $pâˆ¨q â‰¡ qâˆ¨p$   $pâˆ§q â‰¡ qâˆ§p$              |                        |
  | ç»“åˆå¾‹ Associative Laws        |     $(pâˆ¨q)âˆ¨r â‰¡ pâˆ¨(qâˆ¨r)$    $(pâˆ§q)âˆ§r â‰¡ pâˆ§(qâˆ§r)$     |                        |
  | åˆ†é…å¾‹ Distributive Laws       | $pâˆ¨(qâˆ§r) â‰¡ (pâˆ¨q)âˆ§(pâˆ¨r)$   $ pâˆ§(qâˆ¨r) â‰¡ (pâˆ§q)âˆ¨(pâˆ§r)$ |                        |
  | **å¾·Â·æ‘©æ ¹å¾‹ De Morgan's Laws** |        $Â¬(pâˆ¨q) â‰¡ Â¬pâˆ§Â¬q$    $Â¬(pâˆ§q) = Â¬pâˆ¨Â¬q$        | **é‡è¦**               |
  | å¦å®šå¾‹ Negation Laws           |              $pâˆ¨Â¬p â‰¡ T$   $pâˆ§Â¬p â‰¡ F$               |                        |
  | å¸æ”¶å¾‹ Absorption Laws         |           $pâˆ¨(pâˆ§q) â‰¡ p$   $pâˆ§(pâˆ¨q) â‰¡ p$            |                        |
  | é€†å¦å¾‹ Contrapositive Laws     |                   $pâ†’q â‰¡ Â¬qâ†’Â¬p$                    | å‘½é¢˜ä¸å®ƒçš„é€†å¦å‘½é¢˜ç­‰ä»· |
  | **å¯¼å‡ºå¾‹ Exportation Laws**    |                $(pâˆ§q)â†’r â‰¡ pâ†’(qâ†’r)$                 |                        |
  | Absurdity Laws                 |                $(pâ†’q)âˆ§(pâ†’Â¬q) â‰¡ Â¬p$                 |                        |
  | **è•´å«å¾‹ Implication Laws**    |                    $pâ†’q â‰¡ Â¬pâˆ¨q$                    | ç”¨äºå»æ‰ç®­å¤´           |
  | Equivalence Laws               |                $pâ†”q â‰¡ (pâ†’q)âˆ§(qâ†’p)$                 |                        |
### 3. The Dual of a Compound Proposition 

The **dualå¯¹å¶** of compound proposition that contains only the logical operators  $âˆ¨$ , $âˆ§$ and $Â¬$ is the proposition obtained by replacing each $âˆ¨$ by $âˆ§$,each $âˆ§$ by $âˆ¨$,each $T$ by $F$ and each $F$ by $T$. The dual of $S$ is denoted by $S^{*}$.  

*  $S = (p âˆ¨ Â¬q) âˆ§ r âˆ¨ T$      $S^{*} = (p âˆ§ Â¬q) âˆ¨ r âˆ§ F$

* $S = (p âˆ§ q) â†’ (p âˆ¨ q) â‰¡ Â¬(p âˆ§ q) âˆ¨ (p âˆ¨ q)$     $S^{*} = Â¬(p âˆ¨ q) âˆ§ (p âˆ§ q)$ 

ã€Theoremã€‘ let $s$ and $t$ are two compound propositions, **$s$ â‰¡ $t$ if and  only if $s^*$ â‰¡ $t^*$** .

### 4. Functionally Complete Collection of Logical Operators 

åªéœ€è¦éƒ¨åˆ†è¿ç®—ç¬¦å°±å¯ä»¥è¡¨ç¤ºå‡ºæ‰€æœ‰å¯èƒ½çš„è¿ç®—ï¼Œ

ç§°è¿™æ ·çš„ä¸€ä¸ªè¿ç®—ç¬¦é›†åˆä¸º**å…¨åŠŸèƒ½é›†(Functionally Complete Collection)**

**æå°å…¨åŠŸèƒ½é›†**ï¼š$\{Â¬,âˆ¨,âˆ§,â†’,â†” \}\{Â¬,âˆ¨,âˆ§\}, \{Â¬,âˆ§\}\{Â¬,âˆ¨\}, \{âˆ£\}, \{â†“\}$ ç­‰ã€‚

> * $pâˆ¨qâ‰¡Â¬(Â¬pâˆ§Â¬q)$
> * $Â¬pâ‰¡pâˆ£p$
> * $pâˆ§qâ‰¡Â¬(pâˆ£q)â‰¡(pâˆ£q)âˆ£(pâˆ£q)$
> * $pâˆ¨qâ‰¡Â¬(Â¬pâˆ§Â¬q)â‰¡Â¬pâˆ£Â¬qâ‰¡(pâˆ£p)âˆ£(qâˆ£q)$

### 5. Propositional Normal Forms

####  5.1 DNF/CNF

- A **å­—é¢é‡(literal)** is a variable or its negation.
- Conjunctions with literals as conjuncts are called **åˆå–å­å¥(conjunctive clauses)** (clauses). <u>é€šè¿‡ AND è¿æ¥èµ·æ¥çš„ä¸€ç»„å­—é¢é‡</u>ã€‚

**Propositional Normal Forms**ï¼š

- **æå–èŒƒå¼(Disjunctive Normal Form, DNF)**

  A formula is said to be in **disjunctive normal form** if it is written as a disjunction, in which all the terms are conjunctions of literals. 

  > e.g.  $(pâˆ§q)âˆ¨(pâˆ§Â¬q)$

  - æœ€å¤–é¢ä¸€å±‚çš„è¿ç®—ç¬¦éƒ½æ˜¯æå– $âˆ¨$
  - æ‹¬å·å†…çš„è¿ç®—ç¬¦éƒ½æ˜¯åˆå– $âˆ§$

- **åˆå–èŒƒå¼(Conjunctive Normal Form, CNF)**

  > e.g. $(p âˆ¨ q)âˆ§(pâˆ¨Â¬q)$
  
  å’Œ DNF çš„å®šä¹‰ç›¸åï¼›æŠŠ $âˆ§$ å’Œ $âˆ¨$ äº’æ¢ã€‚

#### 5.2 Full DNF & Full CNF

- **Minterm(æå°é¡¹)** : a conjunctive of literals in which each variable is represented <u>exactly once</u>.
- **Maxterm(æå¤§é¡¹)** : a disjunctive of literals in which each variable is represented <u>exactly once</u>.

**Full Disjunctive Normal Form(ä¸»æå–èŒƒå¼)**ï¼š

> e.g. $(p\and \neg q \and r)\or(\neg p \and q \and r)\or (p \and q \and r)=\sum m(3,5,7)$

If a formula is expressed as a disjunction of minterms, it is said to be in **full disjunctive normal form**.

- æ¯ä¸ªæœ€å°é¡¹å¯¹åº”çœŸå€¼è¡¨ä¸­ $T$ çš„æ°å¥½ä¸€è¡Œã€‚

**Full Conjuctive Normal Form(ä¸»åˆå–èŒƒå¼)**ï¼š

> e.g. $(p\or \neg q \or r)\and(\neg p \or q \or r)\and (p \or q \or r)=\sum M(0,2,4)$

- å–å‡ºæ‰€æœ‰çœŸå€¼è¡¨ä¸ºä¸­ä¸º F çš„ä½ç½®ï¼Œå†™å‡º $Â¬f$ã€‚
- å¯¹ $Â¬f$ åº”ç”¨ De Morgan's Lawsï¼Œå¯ä»¥å°†å¼å­ä¸­çš„åˆå–æå–äº’æ¢ï¼Œä»è€Œæ±‚å¾— FCNFã€‚

## 1.4 Predicates and Quantifiers

###  1. Predicates

- **Propositional functionså‘½é¢˜å‡½æ•°** become propositions (and have truth values) when <u>their variables are each replaced by a value from the domain</u> or <u>bound by a quantifier</u>. 

- The statement $P(x_{1}, x_{2}, x_{3})$ is said to be the value of the propositional function $P$ at $x_{1}, x_{2}, x_{3}$. 

-  A statement of the form  $P(x_{1}, x_{2}, x_{3})$ is the value of the propositional function $P$ at the $n-tuple \space (x_1,x_2,â€¦, x_n)$ and $P$ is called **a n-ary predicate nä½è°“è¯**.

  Predicates are also used to establish the correctness of computer programs. 

  * **preconditionså‰ç½®æ¡ä»¶** : the statements that describe **valid input** 
  * **postconditionsåç½®æ¡ä»¶** : the conditions that the **output** should satisfy when the  program has run

### 2. Quantifiers

- **å…¨ç§°é‡è¯(universal quantifier)** $âˆ€$ ï¼šéƒ½æ˜¯çœŸæ‰ä¸ºçœŸï¼Œå­˜åœ¨ä¸€ä¸ªä¸ºå‡å°±ä¸ºå‡ã€‚å¯ä»¥è½¬åŒ–ä¸ºåˆå–ã€‚
- **å­˜åœ¨é‡è¯(existential quantifier)** $âˆƒ$ ï¼šéƒ½æ˜¯å‡æ‰ä¸ºå‡ï¼Œå­˜åœ¨ä¸€ä¸ªä¸ºçœŸå°±ä¸ºçœŸã€‚å¯ä»¥è½¬åŒ–ä¸ºæå–ã€‚
- **å”¯ä¸€é‡è¯(uniqueless quantifier)** $âˆƒ!$ ï¼šæœ‰ä¸”ä»…æœ‰ä¸€ä¸ªä¸ºçœŸæ—¶æ‰ä¸ºçœŸã€‚

æˆ‘ä»¬åœ¨ä½¿ç”¨é‡è¯æ—¶ï¼Œå¯èƒ½åªè¦æ±‚å¯¹äºæŸä¸€èŒƒå›´å†…çš„ $x$ æˆç«‹ï¼Œæˆ‘ä»¬æŠŠæ­¤æ—¶ $x$ çš„å–å€¼èŒƒå›´ç§°ä¸º **è®¨è®ºåŸŸ** (domain of discourse / universe of discourse)ï¼Œä¸€èˆ¬ç®€å†™ä¸º **domain**ã€‚

* **é‡è¯çš„ä¼˜å…ˆçº§(precedence of quantifiers)**
  * The quantifiers âˆ€ and âˆƒ have higher precedence(ä¼˜å…ˆçº§) than **all** the logical operators.
* If t**he domain is finite**, <u>**a universally quantified proposition**</u> is  equivalent to a **conjunction** of propositions without quantifiers and <u>**an existentially quantified proposition**</u> is equivalent to a **disjunction** of  propositions without quantifiers.

### 3. Equivalences in Predicate Logic

Statements involving predicates and quantifiers are logically **equivalent** if and only if they **have the same truth value** no matter

- ä»£å…¥äº†ä»€ä¹ˆè°“è¯é€‰æ‹© which predicates are substituted into these statements and
- ä½¿ç”¨äº†ä»€ä¹ˆè®¨è®ºåŸŸ which domain of discourse is used for the variables in these propositional functions

åŒæ ·ä½¿ç”¨ $â‰¡$ ç¬¦å·æ¥è¡¨ç¤ºè°“è¯é€»è¾‘ä¸­çš„ç­‰å€¼ã€‚

**å¾·æ‘©æ ¹å®šå¾‹(De Morganâ€™s laws)** åœ¨è°“è¯é€»è¾‘ä¸­ä¹Ÿé€‚ç”¨ï¼š

* $Â¬âˆ€xP(x)â‰¡âˆƒxÂ¬P(x)$

* $Â¬âˆƒxP(x)â‰¡âˆ€xÂ¬P(x)$

åªæœ‰åœ¨ $A(x)$ å’Œ $B(x)$ éƒ½è¾“å‡ºçœŸæ—¶ï¼Œ$A(x)âˆ§B(x)$ æ‰ä¸ºçœŸï¼Œæ­¤æ—¶ç¬¬ä¸€ä¸ªç­‰å¼çš„ä¸¤ä¾§éƒ½ä¸ºçœŸï¼Œå¦åˆ™ä¸¤ä¾§éƒ½ä¸ºå‡ã€‚ç±»ä¼¼çš„å¯ä»¥è¯æ˜ç¬¬äºŒä¸ªç­‰å¼ã€‚

* $âˆ€x(A(x)âˆ§B(x))â‰¡âˆ€xA(x)âˆ§âˆ€xB(x)$ , $âˆƒx(A(x)âˆ¨B(x))â‰¡âˆƒxA(x)âˆ¨âˆƒxB(x)$

ä½†æ˜¯å¦‚æœæŠŠä¸Šé¢çš„ç­‰å¼çš„ $âˆ§$ å’Œ $âˆ¨$ äº’æ¢åˆ™ä¸æˆç«‹ã€‚å®¹æ˜“ä¸¾å‡ºåä¾‹ã€‚

* $âˆ€x(A(x)âˆ¨B(x))â‰¡Ì¸âˆ€xA(x)âˆ¨âˆ€xB(x)$ , $âˆƒx(A(x)âˆ§B(x))â‰¡Ì¸âˆƒxA(x)âˆ§âˆƒxB(x)$

<u>For example, $U$ï¼šthe set of real numbersï¼Œ$Q(x)$ï¼š$x$ is a rational numberï¼Œ$F(x)$ï¼š$x$ is an irrational  number</u>

ä½†è¿™ä¸¤ä¸ªå‘½é¢˜åœ¨å…¶ä¸­ä¸€ä¸ªæ–¹å‘ä¸Šæ˜¯æ­£ç¡®çš„ã€‚

* $âˆ€xA(x)âˆ¨âˆ€xB(x)â‡’âˆ€x(A(x)âˆ¨B(x))$ , $âˆƒx(A(x)âˆ§B(x))â‡’âˆƒxA(x)âˆ§âˆƒxB(x)$

æ­¤å¤–ï¼Œè¿˜æœ‰ï¼š

($x$ is not occurring in $P$.)

$âˆ€xA(x)âˆ¨Pâ‰¡âˆ€x(A(x)âˆ¨P)$ , $âˆ€xA(x)âˆ§Pâ‰¡âˆ€x(A(x)âˆ§P)$

$âˆƒxA(x)âˆ¨Pâ‰¡âˆƒx(A(x)âˆ¨P)$ , $âˆƒxA(x)âˆ§Pâ‰¡âˆƒx(A(x)âˆ§P)$

(x is not occurring in $B$.)

$âˆ€x(Bâ†’A(x))â‰¡Bâ†’âˆ€xA(x)$ , $âˆƒx(Bâ†’A(x))â‰¡Bâ†’âˆƒxA(x)$

$âˆ€x(A(x)â†’B)â‰¡âˆƒxA(x)â†’B$ , $âˆƒx(A(x)â†’B)â‰¡âˆ€xA(x)â†’B$

## 1.5 Nested Quantifiers

**åµŒå¥—é‡è¯**ï¼šNest quantifiers are quantfiers that occur within <u>the scope of other quantifiers</u>.

### 1. Order of Quantifiers

é™¤éæ‰€æœ‰é‡è¯éƒ½æ˜¯ $âˆ€$ æˆ–æ‰€æœ‰é‡è¯éƒ½æ˜¯ $âˆƒ$ï¼Œå¦åˆ™é‡è¯çš„é¡ºåºæ˜¯æœ‰æ„ä¹‰çš„ã€‚

The order of nested quantifiers is **important** unless all the quantifiers are universal quantifiers or all the quantifiers are existential quantifiers.

### 2. Prenex Normal Form

* $Q_{1}x_{1}Q_{2}x_{2}...Q_{n}x_{n}B$, where $Q_{i}(i = 1,2,...n)$ is $âˆ€$ or $âˆƒ$, $B$ is quantifier free(ä¸å«é‡è¯çš„å…¬å¼).

å¾—åˆ° **PNF**ï¼ˆ**å‰æŸèŒƒå¼**ï¼‰çš„æ­¥éª¤ï¼š

1. æ¶ˆé™¤æ‰€æœ‰çš„ $â†’ $å’Œ$ â†”$ã€‚
2. å‘å†…ç§»åŠ¨å¦å®šç¬¦å·ï¼Œæ³¨æ„åº”ç”¨å¾·æ‘©æ ¹å®šå¾‹ã€‚
3. å¯¹å˜é‡è¿›è¡Œé‡å‘½åï¼Œç¡®å®šä¸åŒéƒ¨åˆ†çš„å˜é‡ä¸ä¼šå†²çªã€‚
4. æœ€åï¼Œå°†æ‰€æœ‰é‡è¯ç§»åŠ¨åˆ°æœ€å‰é¢ã€‚

## 1.6 Rules of Inference

### 1. Arguments

* An **argumentï¼ˆè®ºæ®ï¼‰** in propositional logic is a sequence of propositions.  All but the final proposition are called **premisesï¼ˆå‰æï¼‰**. The last statement is the **conclusionï¼ˆç»“è®ºï¼‰**.

- An **è®ºæ®(argument)** is a sequence of statements that end with a conclusion

### 2. Valid Arguments & Argument Form

* An **argumentï¼ˆè®ºæ®ï¼‰** is **valid**(æœ‰æ•ˆ) if the truth of all its **premisesï¼ˆå‰æï¼‰** implies that the <u>conclusion</u> is true.   
* An **argument form** is **valid** if no matter which particular propositions are substituted for the propositional variables in its premises, the conclusion is true if the premises are all true.
  * If the premises are $p_{1}, p_{2}, ...p_{n}$ and the conclusion is $q$ , then $p_{1}âˆ§p_{2}âˆ§...âˆ§p_{n}â†’q$ is a **tautology**.

### 3. Rules of Inference

#### 1)Modus Ponens å‡è¨€æ¨ç†

Corresponding Tautology :  $(pâˆ§(pâ†’q))â†’q$

#### 2)Modus Tollens å–æ‹’å¼

Corresponding Tautology :  $(Â¬ q âˆ§(p â†’q))â†’Â¬p$

#### 3)Hypothetical Syllogism å‡è¨€ä¸‰æ®µè®º

 Corresponding Tautology :  $((p â†’q) âˆ§ (qâ†’r))â†’(pâ†’ r)$

#### 4)Disjunctive Syllogism æå–ä¸‰æ®µè®º

 Corresponding Tautology :  $(Â¬pâˆ§(p âˆ¨q))â†’q$

#### 5)Addition é™„åŠ å¾‹

Corresponding Tautology :  $p â†’(p âˆ¨q)$

#### 6)Simplification åŒ–ç®€å¾‹

Corresponding Tautology :  $(pâˆ§q) â†’ p$

#### 7)Conjunction åˆå–å¾‹

Corresponding Tautology : $(ï¼ˆpï¼‰ âˆ§ ï¼ˆqï¼‰) â†’(p âˆ§ q)$

#### 8)Resolution æ¶ˆè§£å¾‹

Corresponding Tautology :  $( (p âˆ¨ q)âˆ§(\neg p âˆ¨ r ) ) \rightarrow(q âˆ¨ r)$

- We use **æ¨ç†å‡†åˆ™(rules of inference)** to construct valid arguments

### 4. Build Valid Arguments 

To prove an argument is valid or the conclusion follows logically from the hypothesesï¼ˆå‡è®¾ï¼‰: 

1. Assume the hypotheses are true. å‡å®šæ‰€æœ‰å‡è®¾æ˜¯å¯¹çš„
2. Use **the rules of inference** and **logical equivalences** to  determine that the conclusion is true.

### 5. Fallacies

#### 1ï¼‰The Fallacy of affirming the conclusion è‚¯å®šç»“è®ºçš„è°¬è¯¯

Method: Reasoning based on $((pâ†’q) âˆ§ q) â†’ p$

#### 2) The Fallacy of denying the hypothesis å¦å®šå‡è®¾çš„è°¬è¯¯

Method: Reasoning based on $((pâ†’q) âˆ§Â¬ p) â†’ Â¬ q$

### 6. Handling Quantified Statements 

**Valid arguments for quantified statements** are a sequence of statements. Each statement is either a premise or follows from previous statements by rules of inference.

#### Universal Instantiation (UI) å…¨ç§°å®ä¾‹

$$
\frac{\forall x P(x)}{\therefore P(c)}
$$

#### Universal Generalization (UG) å…¨ç§°å¼•å…¥

$$
\frac{P(c) \text{ for an arbitrary } c}{\therefore \forall x P(x)}
$$

#### Existential Instantiation (EI) å­˜åœ¨å®ä¾‹

$$
\frac{\exist x P(x)}{\therefore P(c)\text{ for some element}}
$$

#### Existential Generalization (EG) å­˜åœ¨å¼•å…¥

$$
\frac{P(c)\text{ for some element}}{\therefore \exist xP(x)}
$$

### 7. The mixed use of propositional and quantitative propositional reasoning rules

#### Universal Modus Ponens å…¨ç§°å‡è¨€æ¨ç†

$$
\forall x (P(x) \rightarrow Q(x))\\
\frac{
  
  P(a), \text{ where } a \text{ is a particular element in the domain}
}{
  \therefore Q(a)
}
$$

#### Universal Modus Tollens å…¨ç§°å–æ‹’å¼

$$
  \forall x (P(x) \rightarrow Q(x)) \\
\frac{
  \neg Q(a), \text{ where } a \text{ is a particular element in the domain}
}{
  \therefore \neg P(a)
}
$$

## 1.7 Introduction to Proofs

### 1. Some Terminology

-  **Theorem**ï¼ˆå®šç†ï¼‰: A statement that can be shown to be true
   * **Proposition**ï¼ˆå‘½é¢˜ï¼‰: Less important theorem (also called result / fact)
-  **Proof**ï¼ˆè¯æ˜ï¼‰: A valid argument that establishes the truth of a theorem
   * **Axioms**ï¼ˆå…¬ç†ï¼‰: The underlying assumptions about mathematical structures,  or hypotheses of the theorem to be proved, or previously proved theorems. 
   * **Lemma**ï¼ˆå¼•ç†ï¼‰ : A â€˜helping theoremâ€™ or a result which is needed to prove a theorem. 
   * **Corollary**ï¼ˆæ¨è®ºï¼‰ :A result which follows directly from a theorem.
   * **Conjecture**ï¼ˆçŒœæƒ³ï¼‰:  A statement whose truth value is unknown.

### 2. Formal Proofs

**å½¢å¼åŒ–è¯æ˜(formal proof)** v.s. **éå½¢å¼åŒ–è¯æ˜(informal proof)**ï¼š

- Formal Proofsï¼š
  - All steps were supplied
  - The rules for each step in the  argument were given
- Informal Proofs:
  - More than one rule of inference may be used in each step
  - Steps may be skipped
  - The axioms being assumed and the  rules of inference used are not explicity stated

### 3. Proof Methods

#### 3.1 Direct Proof

**ç›´æ¥è¯æ˜æ³•(direct proof)** è¯æ˜ $pâ†’q$ï¼š

- é€šè¿‡**æ¨ç†è§„åˆ™(rules of inference)**ã€å…¬ç†ã€**é€»è¾‘æ’ç­‰å¼(logical equivalences)** ç­‰æ¨å‡º$q$ä¹Ÿä¸ºçœŸã€‚

å…¶ä½™çš„è¯æ˜æ–¹æ³•éƒ½æ˜¯**é—´æ¥è¯æ˜æ³•(indirect proof)**ã€‚

#### 3.2 Proof by Contraposition

åè¯æ³•å¯ä»¥çœ‹åšå¯¹åŸå‘½é¢˜çš„é€†å¦å‘½é¢˜çš„ç›´æ¥è¯æ˜ï¼Œæ ¹æ®é€»è¾‘æ’ç­‰å¼ï¼š$pâ†’qâ‰¡Â¬qâ†’Â¬p$

- å‡è®¾ $Â¬q$ ä¸ºçœŸï¼Œæ¨å‡º $Â¬p$ ä¹Ÿä¸ºçœŸï¼ˆor æ¨å‡º $p$ ä¸ºå‡ï¼‰ï¼Œä»è€Œè¯æ˜åŸå‘½é¢˜ã€‚

#### 3.4 Vacuous and Trivial Proof

- **ç©ºè¯æ˜(vacuous proof)**ï¼šå¯é€šè¿‡è¯æ˜ $p$ ä¸ºå‡æ¥è¯æ˜ $ pâ†’q$ ä¸ºçœŸã€‚
- **å¹³å‡¡è¯æ˜(trivial proof)**ï¼šå¯ä»¥é€šè¿‡è¯æ˜ $q$ ä¸ºçœŸæ¥è¯æ˜ $pâ†’q$ ä¸ºçœŸã€‚

#### 3.5 Proof by Contradiciton

**å½’è°¬è¯æ˜æ³•**çš„æ­¥éª¤

- assumes $p$ is false.
-  derives a contradiction, usually of the form $q âˆ§Â¬ q$ which  establishes $Â¬ p â†’F$.

#### 3.6 Proof of Equivalence 

**ç­‰ä»·è¯æ˜æ³•**

(1)To prove the proposition â€œ$p$ if and only if $q$â€ 

(2)To prove that several propositions $p_{1}, p_{2} ,...,p_{n}$ are equivalent  

* establish the implications $p_{1}â†’ p_{2}, p_{2}â†’p_{3},...,p_{n}â†’p_{1}$  
* $ p_{1}â†”p_{2}â†”...â†”p_{n}â‰¡(p_{1}â†’p_{2})âˆ§(p_{2}â†’p_{3} )âˆ§... âˆ§(p_{n}â†’p_{1})$

## 1.8 Proof Method and Strategy

### 1. Proof Method

#### ç©·ä¸¾å’Œåˆ†æƒ…å†µè¯æ˜æ³• Exhaustive Proof and Proof by Cases

Using the method of proof by cases to show that $(p_{1} âˆ¨ p_{2} âˆ¨â€¦âˆ¨ p_{n}  ) â†’ q$ (ç©·ä¸¾è¯æ˜æ³•)

$ (p_{1} âˆ¨ p_{2} âˆ¨...âˆ¨p_{n} ) â†’ q â‰¡ (p_{1} â†’q) âˆ§(p_{2} â†’q) âˆ§...âˆ§ (p_{n} â†’q)$ (åˆ†æƒ…å†µè¯æ˜æ³•)

#### å­˜åœ¨æ€§è¯æ˜ Existence Proofs

Using **constructive existence proof æ„é€ å­˜åœ¨æ€§è¯æ˜** to establish the truth of $âˆƒxP( x)$. 

* Establish $P(c) $is true for some $c$ in the domain.
* Then $âˆƒxP( x)$ is true by Existential Generalization (EG)

Using **nonconstructive existence proof éæ„é€ å­˜åœ¨æ€§è¯æ˜** to establish the truth of  $âˆƒxP( x)$.  

* Assume no $c$ exists which makes $P(c)$ true and derive a  contradiction 

#### å”¯ä¸€æ€§è¯æ˜ Uniqueness Proofs  

To show that a theorem assert the existence of a unique element with  a particular property. 

$âˆƒx( P(x) âˆ§ âˆ€ y ( yâ‰  xâ†’Â¬P(y) ) )$ 

* Existenceï¼ˆå­˜åœ¨æ€§ï¼‰: We show that an element x with the desired  property exists. 
* Uniquenessï¼ˆå”¯ä¸€æ€§ï¼‰ : We show that if $yâ‰ x$, then y does not have the  desired property. Or, we can show that if $x$ and $y$ both have the  desired property ,then $x=y$.

#### åä¾‹è¯æ˜ Disproof by Counterexample

Using the method of **disproof by counterexample** to establish that $Â¬âˆ€xP(x)$ is true.  

* To construct a $c$ such that $P(c)$ is false. 
* Recall:    $Â¬âˆ€xP(x ) â‡” âˆƒxÂ¬ P(x)$

#### Nonexistence Proofs 

To establish that $Â¬âˆƒxP( x)$ is true .  

* Use a proof by contradiction by assuming there is a $c$ which makes $P(c)$ true . 
* Recall: $Â¬ âˆƒx P(x) â‡” âˆ€ x Â¬ P(x )$

### 2. Proof Strategy

* **Forward reasoning**: Using premises, together with axioms and known theorems to lead to the conclusion.  
* **Backward reasoning**: To reason backward to prove a statement q, we find a statement p that we can prove with the property that $pâ†’q$.

# Ch2 Basic Structures

## 2.1 Sets

ã€Definitionã€‘A **set** is an unordered collection of objects. The objects in a set are called the elements, or members, of the set. A set is said to contain its elements.

### 1. The descriptions of a set

- <u>Roster method èŠ±åå†Œæ–¹æ³•</u> : listing all its members between braces, e.g. $S=\{1,3,5,7,9\}$
- <u>Brace notation with ellipses</u> : e.g. $S=\{1,2,â€¦,99\}$
- <u>Use set builder notation é›†åˆæ„é€ å™¨ (specification by predicates)</u> : $S=\{{xâˆ£P(x)}\}$, which means $S$ contains all the elements from $U$ (**å…¨é›† universal set**) which have the property $P$.
- **ç»´æ©å›¾(Venn diagrams)**

### 2. Relations between Sets

#### Subset

$AâŠ†B$: $A$ is a å­é›†(subset) of the set $B$,  every element of $A$ is also an element of $B$.

$AâŠ†Bâ‡”âˆ€x(xâˆˆAâ†’xâˆˆB)$

#### Equal

$A=B$: $A$ is **ç­‰äº(equal)** to $B$.

$A=Bâ‡”AâŠ†Bâˆ§BâŠ†Aâ‡”âˆ€x[(x âˆˆAâ†’ x âˆˆB) âˆ§ (x âˆˆBâ†’ x âˆˆA)] $

#### Proper Subset

$AâŠ‚B$: $A$ is a **çœŸå­é›†(proper subset)** of the set $B$.

$AâŠ‚Bâ‡”AâŠ†Bâˆ§Aâ‰ Bâ‡”âˆ€x(xâˆˆAâ†’xâˆˆB)âˆ§âˆƒ(xâˆˆBâˆ§xâˆˆÌ¸A)$

#### The Size of a Set 

ã€Definitionã€‘Let S be a set. If there are exactly **n** distinct elements in $S$ where $n$ is a nonnegative integer, we say that $S$ is a finite set and that **n** is the **cardinalityï¼ˆåŸºæ•°ï¼‰**of $S$.

*  Notation:  $âˆ£Sâˆ£$â€”â€” Sçš„**åŸºæ•°** the **cardinality** of $S$

#### Power Sets

Given a set $S$, the **å¹‚é›†(power set)** of $S$ is the set of **all subsets** of the set $S$. **$P(x) $** denotes the power set of $S$.

Example : If $S=\{a,b,c\}$, then $P(S)=\{\empty,\{a\},\{b\},\{c\},\{a,b\},\{a,c\},\{b,c\},\{a,b,c\}\}$

#### Cartesian Products

**[Definition]** The **æœ‰åº n å…ƒç»„(ordered $n-tuple$)** ($a_{1},a_{2},\dots,a_{n}$) is the ordered collection that has $a_{1}$ as its first element,  as its second $a_{2}$ element, â€¦ , and $a_{n}$ as its $n_{th}$ element. In particular, $2-tuples$ are called **ordered pairs**.

 The Cartesian product of $A$ and $B$: $A \times B = \{(a, b)| a \in A, b \in B\}$

The Cartesian product of $A_1 , A_2 , â€¦ , A_n$ : $A_{1}Ã—A_{2}Ã—\dots A_{n}$={$(a_{1},a_{2},\dots,a_{n})âˆ£a_{i}âˆˆA_{i}$, for $i = 1,2,\dots ,n$}

#### Using Set Notation with Quantifiers 

Restrict the domain of a quantified statement explicitly by making use of a particular notation. 

* $âˆ€xâˆˆS(P (x)):   âˆ€x(xâˆˆS â†’ p(x))   $     
* $âˆƒxâˆˆS(P (x)):    âˆƒ x(xâˆˆS âˆ§ p(x)) $

#### Truth Sets of Quantifiers

Given a predicate P and a domain $D$. 

The **çœŸé›†(truth set)** of $P$ is the set of elements $x$ in $D$ for which $P(x)$ is true. Namely, the power set of $P$ is {$xâˆˆDâˆ£P(x)$}

## 2.2  Set Operations

#### Union

$AâˆªB=${$xâˆ£xâˆˆAâˆ¨xâˆˆB$}

#### Intersection

$Aâˆ©B=${$xâˆ£xâˆˆAâˆ§xâˆˆB$}

Note : Two sets are called disjoint if their intersection is the empty set,namely $Aâˆ©B = Ã˜ $

#### Complement

$\overline A=\{{xâˆ£xâˆˆÌ¸A, xâˆˆU}\}$ is the **è¡¥é›†(complement)** of the set A.

Let $U$ be universal set. The complement of the set $A$  denoted by $\overline A$, is **the complement of $A$with respect to $U$**, namely, $U â€“ A$. (The complement of $A$ is sometimes denoted by $A^{c}$ .)

#### Difference

$Aâˆ’B=\{{xâˆ£xâˆˆAâˆ§xâˆˆÌ¸B}\}$ 

the set containing those elements that are <u>in A but not in B</u>.

#### Symmetric difference

$AâŠ•B=(AâˆªB)âˆ’(Aâˆ©B)$

the set containing those elements that are in <u>A but not in B</u> or <u>in B but not in A</u>.

#### The Cardinality of a Union of Two Sets

The principle of Inclusion - exclusion **å®¹æ–¥åŸç†**ï¼š$\ |A \cup B| = |A| + |B| - |A \cap B| \ $

#### é›†åˆæ’ç­‰å¼ Set Identities

| Identity                                                 | Name                |
| :------------------------------------------------------- | ------------------- |
| $ A \cup \emptyset = A, A \cap U = A $                   | Identity laws       |
| $A \cup U = U, A \cap \emptyset = \emptyset $            | Domination laws     |
| $ A \cup A = A, A \cap A = A $                           | Idempotent laws     |
| $ \overline{\overline{A}} = A $                          | Complementation law |
| $ A \cup B = B \cup A, A \cap B = B \cap A $             | Commutative laws    |
| $ A \cup (B \cup C) = (A \cup B) \cup C $                | Associative laws    |
| $A \cap (B \cap C) = (A \cap B) \cap C $                 |                     |
| $ A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$        | Distributive laws   |
| $ A \cup (B \cap C) = (A \cup B) \cap (A \cup C) $       |                     |
| $ \overline{A \cup B} = \overline{A} \cap \overline{B} $ | De Morganâ€™s laws    |
| $ \overline{A \cap B} = \overline{A} \cup \overline{B} $ |                     |

## 2.3 Functions

### Introduction

**[Definition]** : Let A and B be nonempty sets. A function $f$ from $A$ to $B$ is an assignment of each element of $A$ to exactly one element of $B$.

**Denode**: $f:Aâ†’B$   or   $âˆ€a(aâˆˆAâ†’âˆƒ!b(bâˆˆBâˆ§f(a)=b))$

* We write $f(a) = b$ if b is the unique element of B assigned by the  function f to the element a of A.  Functions are sometimes called **mappingsï¼ˆæ˜ å°„ï¼‰** or **transformationsï¼ˆå˜æ¢ï¼‰**.

**Given a function $f: A â†’ B$:** 

 $f$ maps $A$ to $B$ or $f$ is a mapping from $A$ to $B$.

* A is called the domain of $f$, B is called the codomain of $f$.
* If $f(a) = b$, then b is called the **image(åƒ)** of a under $f$, a is called the **preimage(åŸåƒ)** of b.T
* The range of $f$ is the set of <u>all images of points in $A$ under $f$</u>. We denote it by $f(A)$.
*  Two functions are **equal** when they have the same domain, the same codomain and map each element of the domain to the same element of the codomain.

ã€Definitionã€‘Let  $f_{1}$ and $f_{2}$ be functions from $A$ to $R$. Then $ (f_{1} + f_{2})(x) = f_{1}(x)+ f_{2}(x)$   $ (f_{1}f_{2})(x) = f_{1}(x) f_{2}(x)$ 

ã€Definitionã€‘ Let $f$ be a function from A to B and let $S$ be a subset of A. The  image of $S$  is the subset of B that consists of the images of the elements of S. We denote the image of $S$ by $f(S)$, so that $f (S) = \{{ f(s) | sâˆˆS }\}$

### One-to-one Functions

A function f is **å•å°„å‡½æ•°(one-to-one function / injection)** , or **å•å°„çš„(injective)** if

$âˆ€aâˆ€b(f(a)=f(b)â†’a=b)$ 

### Onto Functions

A function f from A to B is called **æ»¡å°„å‡½æ•°(onto function / surjection)**, or **æ»¡å°„çš„(surjective)** if

$âˆ€bâˆˆBâˆƒaâˆˆA(f(a)=b)$

### One-to-one Correspondence Functions

The function f is a **one-to-one correspondence**, or a **bijection**(åŒå°„), if it is both **one-to-one** and **onto**.

> ![image-20250615162038356](image-20250615162038356.png)

### Inverse Functions

Let $f$ be a bijection from A to B. Then the inverse function of $f$, denoted $f ^{-1}$,  is the function from B to A defined as $f  ^{-1} ( b ) = a$ iff $f ( a ) = b$

### Floor and Ceiling Function

The ceiling function $f (x)$ is the smallest integer greater than or equal to x

The floor function $f (x)$ is the biggest integer smaller than or equal to x

## 2.4 Sequences and Summations

### 1. Introduction

[Definiton] A **æ•°åˆ—(sequence)** is a function from a subset of the set of integers (usually either the set {0,1,2,â€¦} or the set {1,2,3,â€¦} ) to a set S. We use the notation $a_{n}$ to denote the image of the integer n. We call $a_{n}$ a **term(é¡¹)** of the sequence.

### 2. Some Familiar Sequences

A **ç­‰æ¯”æ•°åˆ—(geometric progression)** is a sequence of the form$a, ar, ar^{2}, â€¦, ar^{n}$

where the initial term a and the **å…¬æ¯”(common ratio)** r are real numbers.

An **ç­‰å·®æ•°åˆ—(arithmetic progression)** is a sequence of the form$a, a+d, a+2dâ€‰â€¦, a+nd$

where the initial term a and the **å…¬å·®(common difference)** d are real numbers.

### 3. Strings

[Definition] A string is a finite sequence of characters from a finite set (an  alphabet).

### 4. Recurrence Relations

 [Definition] A **recurrence relation(è¿­ä»£å…³ç³»)** for the sequence $\{a_{n}\}$ is an equation that expresses an in terms of one or more of the previous terms of the  sequence, namely, $a_{0}, a_{1}, â€¦, a_{n-1}$, for all integers n with $n â‰¥ n_{0}$, where $n_{0}$  is a nonnegative integer.  

* A sequence is called a solution of a recurrence relation if its terms  satisfy the recurrence relation. 
* The initial conditions for a sequence specify the terms that precede the  first term where the recurrence relation takes effect. 

## 2.5 Cardinality of Sets

* ã€Definitionã€‘: The sets $A$ and $B$ have the same cardinality (denoted by $| A |
  = | B |$) iff there exists a <u>one-to-one correspondence (bijectionåŒå°„)</u> from $A$ to $B$
  * This provides a **relative measure** of the sizes of two sets, rather than a measure of the size of one particular set.

* ã€Definitionã€‘: If there is a <u>one-to-one functionå•å°„</u> form $A$ to $B$, the cardinality of $A$ is less than or the same as cardinality of B ($|A|â‰¤|B|$). When $|A|â‰¤|B|$ and $A$ and $B$ have different cardinality, we say that the cardinality of $A$ is less than the cardinality of B and we write $|A|<|B|$


### 1. Countable Sets

* ã€Definitionã€‘: A set that is either finite or has the same cardinality as <u>the set of positive integers</u> is called **countableå¯æ•°**

* When an infinite set is countable (countably infinite) , its cardinality is **$â„µ_{0}$** (where $â„µ$ is aleph, the 1st letter of the Hebrew alphabet). We write *$|S| = â„µ_{0}$* and say that S has cardinality ***â€œ aleph null é˜¿åˆ—å¤«é›¶ â€***

* An infinite set is **countable** if and only if it is possible to **list the elements of the set in a sequence** (indexed by the positive integers, be expressed in terms of a sequence $a_{1},a_{2},\dots, a_{n} ,\dots $where $a_{1}=f(1),a_{2}=f(2),\dots, a_{n} =f(n),\dots $
* æ­£æœ‰ç†æ•°é›†$Q_{+}$æ˜¯å¯æ•°çš„

* 0 åˆ° 1 ä¹‹é—´çš„å®æ•°é›†ä¸å¯æ•°
* $[1,2]$å’Œ$(1,2)$ç­‰åŠ¿
* $N$çš„æœ‰é™å­é›†éƒ½å¯æ•°

### 2. Uncountable Sets

> * If set $A$ and $B$ is countable, then $A\cup B$ is countable.
> * **æœ‰é™ä¸ª**å¯æ•°é›†åˆçš„äº¤é›†æ˜¯å¯æ•°çš„

ã€Theoremã€‘The set of real numbers between $0$ and $1$ is **uncountable**.

* use an important proof method known as the **Cantor diagonalization argument**ï¼ˆCantor å¯¹è§’åŒ–è®ºè¯ï¼‰

ã€Theoremã€‘The set of real numbers is **uncountable**.

* Any set with an uncountable subset is uncountable.
*  $|R|= â„µ$
* It is said to have the cardinality of the continuum, c.

### 3. Results about cardinality

1) No infinite set has a smaller cardinality than a countable set.
2) If A and B are countable, $A\cup B$ is countable.
3) The union of finite number of countable sets is countable.
4) The union of a countable number of countable sets is countable

### 4. Uncomputable Function

ã€Definitionã€‘A function is **computable** if there is a computer program in some programming language that finds the values of this function. If a function is not computable, we say it is **uncomputable**.

### 5. The Continum Hypothesis

* åº·æ‰˜å®šç†ï¼ˆCantor's Theoremï¼‰The cardinality of the power set of an arbitrary set has a greater cardinality than the original arbitrary set. ( $âˆ£P(â„µ_{k})âˆ£=âˆ£â„µ_{k+1}âˆ£$ )
* The power set of $Z^{+}$ and the set of real numbers $R$ have the  same cardinality. $|P(Z^{+})|=|R|= c$
* The continuum hypothesis asserts that there is **no cardinal number** a such that  $â„µ_{0} < a <  c$.

# Ch3 Algorithm

## 3.1 ç®—æ³• Algorithms

[Definition] : An **algorithm** is a finite set of precise instructions for  performing a computation or for solving a problem.

### ç®—æ³•çš„æ€§è´¨ Properties of Algorithms

- **è¾“å…¥(input)**ï¼šAn algorithm has input values from a specified set.
- **è¾“å‡º(output)**ï¼šFrom each set of input values, an algorithm produces output values from a specified set.
- **ç¡®å®šæ€§(definiteness)**ï¼šç®—æ³•çš„æ¯ä¸€æ­¥éƒ½åº”è¯¥è¢«ç²¾ç¡®å®šä¹‰ã€‚The steps of an algorithm must be defined precisely.
- **æ­£ç¡®æ€§(correctness)**ï¼šç®—æ³•åº”è¯¥ç»™å‡ºæ­£ç¡®çš„è¾“å‡ºç»“æœã€‚An algorithm should produce the correct output values for each set of input values.
- **æœ‰é™æ€§(finiteness)**ï¼šç®—æ³•åº”å½“åœ¨æœ‰é™æ­¥å†…ç»“æŸã€‚An algorithm should produce the desired output after a finite number of steps for any input in the set.
- **æœ‰æ•ˆæ€§(effectiveness)**ï¼šç®—æ³•çš„æ¯ä¸€æ­¥éƒ½å¯ä»¥è¢«æœ‰æ•ˆæ‰§è¡Œã€‚Each step of an algorithm must be executed exactly and in a finite amount of time.
- **é€šç”¨æ€§(generality)**ï¼šæˆ‘ä»¬çš„ç®—æ³•åº”è¯¥å¯¹äºä»»æ„ç¬¦åˆæ¡ä»¶çš„è¾“å…¥éƒ½åº”ç”¨ï¼Œè€Œä¸æ˜¯åªé€‚ç”¨æŸäº›ç‰¹å®šçš„è¾“å…¥ã€‚The procedure should be applicable for all problems of the desired form, not just for a particular set of input values.

## 3.2 å‡½æ•°çš„å¢é•¿ The Growth of Functions

#### è®°å· Notations

**å¤§ O è®°å·(==Big-O notation==)**ï¼šLet $f$ and $g$ be functions from $Z$ (or $R$) to $R$. We say that â€œ$f(x)$ is $O(g(x))$â€ if there are constants $C$ and $k$ such that $âˆ£f(x)âˆ£â‰¤Câˆ£g(x)âˆ£$ whenever $x>k$.

**å¤§Î©è®°å·(==Big-Omega notation==)**ï¼šLet $f$ and $g$ be functions from $Z$ (or $R$) to $R$. We say that â€œ$f(x)$ is $\Omega(g(x))$â€ if there are constants $C$ and $k$ such that $âˆ£f(x)âˆ£\geq Câˆ£g(x)âˆ£$ whenever $x>k$.

**å¤§Î˜è®°å·(==Big-Theta notation==)**ï¼šLet $f$ and $g$ be functions from $Z$ (or $R$) to $R$. We say that â€œ$f(x)$ is $\Theta(g(x))$â€ if â€œf$f(x)$ is $\Omega(g(x))$â€ and â€œ$f(x)$ is $\Omega(g(x))$â€ , i.e., there are constants $C_1,C_2$ and $k$ such that $0â‰¤C_1g(x)â‰¤f(x)â‰¤C_2g(x)$ whenever $x>k$.

### The Growth of Combinations of Functions

* If $f_1(x)$ is $O(g_1(x))$ and  $f_2(x)$ is $O(g_2(x))$, then $(f_1 + f_2)(x)$ is $O(max(g_1(x),g_2(x)))$. 
* If  $f_1 (x)$ and $f_2 (x)$ are both $O(g(x))$, then $( f_1 + f_2 )(x)$ is $O(g(x))$.
* If  $f_1(x)$ is $O(g_1(x))$ and $f_2(x)$ is $O(g_2(x))$, then $(f_1f_2)(x)$ is $O(g_1(x)g_2(x))$.

## 3.3 ç®—æ³•çš„å¤æ‚åº¦ Complexity of Algorithms

<img src="images/image-20250324193656175.png" alt="image-20250324193656175" style="zoom:50%;" />

# Ch4 The Number Theory and Cryptography

## 4.1 Divisibility and Modular Arithmetic
### 1. Division

**[Definition]** ï¼šIf $a$ and $b$ are integers with $a \neq 0$, then $a$ divides $b$ if there exists an integer $c$ such that $b=ac$

* When $a$ divides $b$ we say that $a$ is a factor or divisor of $b$ and that $b$ is a multiple of $a$.
*  The notation $a | b$ denotes that $a$ divides $b$.
*  If $a | b$ , then **$b/a$**  is an integer.
*  If $a$ does not divide $b$, we write $a âˆ¤ b$

#### Properties of Divisibility

**Theorem**: Let a, b, and c be integers, where $ğ’‚ â‰  ğŸ$.

* If $ğ‘ | ğ‘$ and $ğ‘ | ğ‘$ , then $ğ‘ | (ğ‘ + ğ‘)$
*  If $ğ‘ | ğ‘$ , then $ğ‘ | ğ‘ğ‘$ for all integers $c$
*  If $ğ‘ | ğ‘$ and $ğ‘ | ğ‘$, then $ğ‘ | ğ‘$

**Corollary**: If a, b, and c be integers, where $a \neq 0$, such that $ğ‘ | ğ‘$ and $ğ‘ | c$, then $ğ‘ | mğ‘+nc$ whenever m and n are integers.

### 2. Division Algorithm

If $a$ is an integer and $d$ a positive integer, then there are unique integers $q$ and $r$, with $0 \leq r < d$, such that $a = dq + r$

* d is called the **divisor é™¤æ•°** 
* a is called the **dividend è¢«é™¤æ•°** 
* q is called the **quotient å•†**  **<u>q = a div d</u>**
* r is called the **remainder ä½™æ•°(éè´Ÿ)** **<u>r = a mod d</u>**

### 3. Congruence Relation

**[Definition]** : è‹¥ $a$ å’Œ $b$ ä¸ºæ•´æ•°ï¼Œ$m$ ä¸ºæ­£æ•´æ•°ï¼Œå½“ m èƒ½æ•´é™¤ $a âˆ’ b$ æ—¶ï¼Œç§° $a$ ä¸ $b$ å¯¹æ¨¡ $m$ åŒä½™ã€‚

* The notation $a â‰¡ b (mod$  $m)$ says that a is congruent to b modulo m.
* If a is not congruent to b modulo m, we write $a â‰¢ b (mod$  $m)$

**Theorem**: Let m be a positive integer. The integers a and b are congruent modulo m if and only if there is an integer k such that $a = b+km$

#### 3.1 Congruences of Sums and Products

**Theorem**: Let m be a positive integer. If $a â‰¡ b\pmod m$ and $c â‰¡ d \pmod m$, then $a+c â‰¡ b+d\pmod m$ and $ac â‰¡ bd\pmod m$

#### 3.2 Algebraic Manipulation of Congruences

- **åœ¨åŒä½™å¼ä¸¤è¾¹åŒæ—¶ä¹˜ä»¥ä¸€ä¸ªæ•´æ•°åä»ç„¶åŒä½™**
  - If  $a \equiv b \pmod{m} $ holds then  ==$c \cdot a \equiv c \cdot b \pmod{m}$== , where $c $ is any integer

- **åœ¨åŒä½™å¼ä¸¤è¾¹åŒæ—¶åŠ ä¸Šä¸€ä¸ªæ•´æ•°åä»ç„¶åŒä½™**
  - If  $a \equiv b \pmod{m} $ holds then  ==$a+c \equiv b+c \pmod{m}$== , where $c $ is any integer

- **åœ¨åŒä½™å¼ä¸¤è¾¹åŒæ—¶é™¤ä»¥ä¸€ä¸ªæ•´æ•°ååŒä½™æ— æ³•ç¡®å®š**

**[Corollary]** :

* ==$(a + b) \mod m = ((a \mod m) + (b \mod m)) \mod m$==
* ==$ab \mod m = \left((a \mod m)(b \mod m)\right) \mod m$.==

### 4. Arithmetic Modulo m

**[Definitions]** : Let $Z_m$ be the set of nonnegative integers less than $m$: { $0,1, \dots , m âˆ’ 1$ }

* The operation **+m** is defined as $a+ _mb = (a+b)\mod m $. This is **addition modulo m**.
* The operation **âˆ™m** is defined as $a â‹… _mb = (a\cdot b)\mod m $. This is **multiplication modulo m**.
* Using these operations is said to be doing <u>***arithmetic modulo mç®—æœ¯æ¨¡ m***</u>

The operations **+m** and **Â·m** satisfy many of the same properties as ordinary addition and multiplication.

* **Closure å°é—­æ€§**

  If $a$ and $b$ belong to $Z_m$, then $a +_m b \in Z_m$ and $a Â·_m b \in Z_m$ .

* **Associativity ç»“åˆå¾‹**

  If $a$, $b$, and $c $ belong to $Z_m$, 

  then $(a +_mb) + _m c = a +_m (b +_m c)$ and $(a Â·_m b) Â·_m c = a Â·_m (b Â·_m c)$.

* **Commutativity äº¤æ¢å¾‹**

  If a and b belong to $Z_m$, 

  then $a +_m b = b +_m a$ and $a Â·_m b = b Â·_m a$.

* **Identity elements å•ä½å…ƒ**

  The elements 0 and 1 are identity elements for addition and multiplication modulo m, respectively. 

  If a belongs to $Z_m$, 

  then $a +_m 0 = a$ and $a Â·_m 1 = a$.

* **Additive inverses åŠ æ³•é€†å…ƒ**

  If $ğ‘ â‰  0$ belongs to $ğ‘_ğ‘š$ ,

  then $ğ‘š âˆ’ ğ‘$ is the additive inverse of **a modulo m** and 0 is its own additive inverse. 

  * $ğ‘ + _ğ‘š (ğ‘š âˆ’ ğ‘ ) = 0$ and $0 +_ğ‘š 0 = 0$

* Distributivity åˆ†é…å¾‹

  If a, b, and c belong to $ğ‘_ğ‘š$ , 
  
  then $ğ‘ Â·_ğ‘š (ğ‘ +_ğ‘š ğ‘) = (ğ‘Â· _ğ‘š ğ‘) + _ğ‘š (ğ‘ +_ğ‘š ğ‘)$ and $(ğ‘ +_ğ‘š ğ‘) Â·_ğ‘š ğ‘ = (ğ‘ Â·_ğ‘š ğ‘) +_ğ‘š (ğ‘Â·_ğ‘š ğ‘)$

## 4.3 Primes and Greatest Common Divisors

### 1. Primes

**[Definition]** : A positive integer p greater than 1 is called prime if the only positive factors of p are 1 and p. A positive integer that is greater than 1 and is not **primeç´ æ•°** is called **compositeåˆæ•°**

**Theorem**: There are infinitely many primes. (Euclid) ç´ æ•°çš„æ— é™æ€§

**[Definition]** : Prime numbers of the form $2^p âˆ’ 1$, where $p$ is prime, are called **Mersenne primesæ¢…æ£®æ•°**

### 2. The Fundamental Theorem of Arithmetic

**Theorem 1**: Every positive integer greater than 1 can be written uniquely as a prime or as the product of two or more primes where the prime factors are written in order of nondecreasing size. 

**Theorem 2**: If n is a composite integer, then n has a prime divisor less than or equal to $\sqrt n$

è‹¥ n ä¸ºåˆæ•°ï¼Œåˆ™ n å¿…æœ‰ä¸€ä¸ªè´¨å› æ•°å°äºæˆ–ç­‰äº$\sqrt n$

### 3. The Sieve of Eratosthenes

***The Sieve of Eratosthenes*** can be used to find all primes not  exceeding a specified positive integer n.  

> æ–¹æ³•ï¼šæ‰¾å‡ºæ‰€æœ‰ä¸è¶…è¿‡ n çš„è´¨æ•°ï¼Œç„¶åä»å°åˆ°å¤§ä¾æ¬¡å°†å®ƒä»¬çš„å€æ•° ( ä¸è¶…è¿‡ n ) åˆ å»ï¼Œå‰©ä¸‹çš„æ•°å°±æ˜¯ä¸è¶…è¿‡ n çš„è´¨æ•°ã€‚

* For example, $n=100$ Begin with the list of integers between 1 and 100. 
  * â‘  Delete all  the integers, other than 2, divisible by 2. 
  * â‘¡ Delete all the integers, other than 3, divisible by 3. 
  * â‘¢ Next, delete all the integers, other than 5, divisible by 5. 
  * â‘£ Next, delete all the integers, other than 7, divisible by 7. 
  * â‘¤ Since all the remaining integers  are not divisible by any of the previous integers, other than 1, the primes are: $\{2,3,5,7,11,15,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97\}$

### 4. ç´ æ•°çš„åˆ†å¸ƒ

**Prime Number Theorem**: The ratio of the number of primes not exceeding $x$ and $x/lnx$ approaches $1$ as $x$ grows without bound. 
$$
\lim_{x\rightarrow \infty}\frac{\pi(x)}{x/lnx}=1
$$


### 5. Greatest Common Divisor 

**[Definition]** : Let $a$ and $ b$ be integers, not both zero. The largest integer d such that ğ’… | ğ’‚ and also ğ’… | ğ’ƒ is called the greatest common divisor of $a$ and $b$. The greatest common divisor of a and b is denoted by $gcd(a,b)$

**[Definition]** : The integers $a$ and $b$ are **relatively prime** if their greatest common divisor is 1

### 6. Least Common Multiple 

**[Definition]** : The least common multiple of the positive integers $a$ and $b$ is the smallest positive integer that is divisible by both a and b. It is denoted by $lcm(a,b)$

**[Theorem]** : Let a and b be positive integers. Then $ğ‘ğ‘ = gcd(ğ‘, ğ‘) Â· ğ‘™ğ‘ğ‘š(ğ‘, ğ‘)$

### 7. Euclidean Algorithm

The Euclidian algorithm is an efficient method for computing the greatest common divisor of two integers.

* let $a=bq+r$, then $gcd(a,b) = gcd(b,r)$

<img src="images/image-20250326103806432.png" alt="image-20250326103806432" style="zoom: 80%;" />

### 8. gcds as Linear Combinations 

**è£´èœ€å®šç† BÃ©zoutâ€™s Theorem** : If a and b are positive integers, then there exist integers s and t such that ==$ğ’ˆğ’„ğ’…(ğ’‚, ğ’ƒ) = ğ’”ğ’‚ + ğ’•ğ’ƒ$==

**[Definition]** : If a and b are positive integers, then integers $s$ and $t$ such that $gcd(a,b) =sa+tb$ are called **BÃ©zout coefficients è£´èœ€ç³»æ•°** of a and b. The equation  $gcd(a,b) =sa+tb$ is called **BÃ©zoutâ€™s identity è£´èœ€æ’ç­‰å¼**

* Lemma : If a, b, and c are positive integers such that $gcd(a,b)=1$ and ğ’‚ |ğ’ƒğ’„, then ğ’‚ | ğ’„
* Lemma : If p is prime and $p | a_1 a_2 \dots a_n$, then $p | a_i$ for some i

### 9. Dividing Congruences by an Integer 

**[Theorem]** : Let m be a positive integer and let a, b, and c be integers.

If $ğ’‚ğ’„ â‰¡ ğ’ƒğ’„ \pmod ğ’$ and $ğ’ˆğ’„ğ’…(ğ’„, ğ’) = ğŸ$, then $ğ’‚ â‰¡ ğ’ƒ \pmod ğ’$

## 4.4 Solving Congruences

### 1. Linear Congruences

**[Definition]** : A congruence of the form $ax â‰¡ b \pmod m$, where m is $a$ positive integer, $a$ and $b$ are integers, and $x$ is a variable, is called a linear congruence.

* *The solutions to a linear congruence* $ax â‰¡ b \pmod m$ are all integers x that satisfy the congruence

### 2. Inverse of a modulo m

**[Definition]**: An integer $\overline{a}$ such that $\overline a a â‰¡ 1 \pmod m$ is said to be **an inverse of a modulo m**.

**Theorem** : è‹¥$a,m$äº’è´¨å¹¶ä¸”$m\geq1$ï¼Œåˆ™$aæ¨¡m$çš„é€†å­˜åœ¨ï¼Œä¸”å¯¹æ¨¡$m$çš„é€†æ˜¯å”¯ä¸€çš„ã€‚

* The Euclidean algorithm and BÃ©zout coefficients gives us a **systematic approaches** to finding inverses

  if $sa+tm=1$, then ==$s a â‰¡ 1 \pmod m$==, ==$s=\overline{a}$==

### 3. The Chinese Remainder Theorem

$$
x \equiv a_1 \pmod {m_1} \\
x \equiv a_2 \pmod {m_2} \\
\dots \\
x \equiv a_n \pmod {m_n}
$$

$gcd(m_i,m_j)=1(i \neq j)$ and $m_i > 1$

To construct a solution

* First let $M_k = {m}/{m_k}$ for $ k = 1, 2, ..., n$, where $m = m_1 m_2 \dots m_n $ .
  Since $\text{gcd}(m_k, M_k) = 1 $, there is an integer $ y_k $, an inverse of $M_k $ modulo $ m_k $, such that $M_k y_k \equiv 1 \ (\text{mod} \ m_k)$

* Form the sum

  ==$ x = a_1 M_1 y_1 + a_2 M_2 y_2 + \cdots + a_n M_n y_n$==

* Note that because $M_j \equiv 0 \ (\text{mod} \ m_k) $ whenever $ j \neq k $, all terms except the $k$th term in this sum are congruent to $0$ modulo $m_k $.

* Because $M_k y_k \equiv 1 \ (\text{mod} \ m_k) $, we see that $ x \equiv a_k M_k y_k \equiv a_k (\text{mod} \ m_k) $, for $k = 1, 2, ..., n $.
  Hence, $x$  is a simultaneous solution to the $n$ congruences.

#### åå‘æ›¿æ¢ Back Substitution

1. The first congruence can be rewritten as $x = 5t +1$, where t is an integer
2. Substituting into the second congruence yields  $5t +1 â‰¡ 2 (mod 6).$ 
3. Solving this tells us that  $t â‰¡ 5 (mod 6)$
4.  $t = 6u + 5$ where $u$ is an integer.  
5.  Substituting this back into $x = 5t +1$,  gives $ x = 5(6u + 5) +1 = 30u + 26$
6. Inserting this into the third equation gives $30u + 26 â‰¡ 3 (mod 7)$
7. Solving this congruence tells us that $u â‰¡ 6 (mod 7)$
8. $u = 7v + 6$, where $v$ is an integer
9. Substituting this expression for $u$ into $x  =  30u + 26$, tells us that $x  =  30(7v + 6) + 26 = 210v + 206$
10. Translating this back into a congruence we find the solution $x â‰¡ 206 (mod 210)$

### 4. Computer Arithmetic with Large Integers

Suppose that $m_1, m_2, \dots, m_n$ are pairwise relatively prime moduli and let $m$ be their product.  By the Chinese remainder theorem, we can show that an integer $a$ with $0 â‰¤ a < m$ can be  uniquely represented by the n-tuple consisting of its remainders upon division by $m_i , i = 1,  2, â€¦ , n$ That is, we can uniquely represent $a$ by ==$(a \mod m_1, a \mod m_2, \dots , a \mod m_n)$==

### 5. Fermatâ€™s Little Theorem

> å¦‚æœ $p$ æ˜¯è´¨æ•°ï¼Œ$a$ ä¸ºæ•´æ•°ï¼Œä¸” $pâˆ¤a$ï¼Œé‚£ä¹ˆ $a^p â‰¡ a \pmod p$

**[Theorem]** : If $p$ is prime and $a$ is an integer not divisible by $p$, then $a^{p-1} â‰¡ 1 \pmod p$ Furthermore, for every integer $a$ we have ==$a^p â‰¡ a \pmod p$==

* **Note**ï¼šTo find an mod $p$, we only need to compute $a^r$ mod $p$, where $n = q(p âˆ’ 1) + r, 0 \leq r \leq p âˆ’ 1$

### 6. Pseudoprimes

* By Fermatâ€™s little theorem $n > 2$ is prime, where $2^{n-1} â‰¡ 1 \pmod n$  
* But if this congruence holds, $n$ may not be prime.

Given a positive integer $n$, such that  $2^{n-1} â‰¡ 1 \pmod n$: 

* If $n$ does not satisfy the congruence, it is **compositeåˆæ•°**.  
* If $n$ does satisfy the congruence, it is either **prime** or **pseudoprime**

### 7. Carmichael  Numbers

**[Definition]** : A composite integer $n$ that satisfies the congruence $bn-1 â‰¡ 1 \pmod n$ for all positive integers $b$ with $gcd(b,n) = 1$ is called a ==Carmichael number==

# Ch5 Induction and Recursion

## 5.1 Mathematical Induction 

### 1. Principle of Mathematical Induction

* **The (first) principle of Mathematical Induction** 

  $ (P(1) âˆ§âˆ€ k(P(k) â†’ P(k+1))) â†’âˆ€ n P(n)$ where the domain is the set of positive integers

### 2. The procedure

1. Inductive base: Establish $P(k) $

2. Inductive step: Prove that $P(n) â†’ P(n+1)$ for $nâ‰¥ k $

   Conclusion: The inductive base and the inductive step together imply $P(n) âˆ€ n â‰¥ k$

## 5.2 Strong Induction and Well-ordering

### 1. Strong Induction

* The Second Principle of Mathematical Induction*æ•°å­¦å½’çº³æ³•ç¬¬äºŒåŸç†*  (==Strong Induction==,  complete induction) 

$(P(n_0 )âˆ§âˆ€k ( k\geq n_0 âˆ§P(n_0 )âˆ§P(n_0 +1)âˆ§â€¦âˆ§P(k) â†’  P(k+1)))â†’ âˆ€n P(n)$

**The procedure** : 

1. *BASIS STEP* : Establish $P(n_0 )$
2. *INDUCTIVE STEP* : Prove $P(n_0 )âˆ§P(n_0 +1)âˆ§ . . . âˆ§P(k) â†’ P(k+1)$ 
3. *CONCLUSION*: The inductive base and the inductive step allow one to conclude that $P(n) \space âˆ€nâ‰¥n_0$

### 2. Using Strong Induction in Computational Geometry

**Some terms** :

- **å¤šè¾¹å½¢ (polygon)**ï¼šç”±ä¸€ç³»åˆ—çº¿æ®µ $s_1,s_2,â€¦,s_n$( å®ƒä»¬è¢«ç§°ä¸º**è¾¹ (sides)**) æ„æˆçš„å°é—­å‡ ä½•å›¾å½¢
- **é¡¶ç‚¹ (vertex)**ï¼šå¤šè¾¹å½¢ä¸­æ¯å¯¹è¿ç»­çš„è¾¹ $s_i,s_{i+1}(i=1,2,â€¦,nâˆ’1)$ä¸Šçš„å…¬å…±ç«¯ç‚¹
- æ¯ä¸ªç®€å•å¤šè¾¹å½¢å°†å¹³é¢åˆ’åˆ†æˆ 2 ä¸ªåŒºåŸŸï¼š
  - **å†…éƒ¨ (interior)**ï¼šæ›²çº¿å†…çš„æ‰€æœ‰ç‚¹
  - **å¤–éƒ¨ (exterior)**ï¼šæ›²çº¿å¤–çš„æ‰€æœ‰ç‚¹
- **å‡¸ (convex)**å¤šè¾¹å½¢ï¼šä»»æ„ä¸¤ä¸ªé¡¶ç‚¹é—´çš„çº¿æ®µä½äºå¤šè¾¹å½¢çš„å†…éƒ¨æˆ–è¾¹ç•Œä¸Šã€‚å¦åˆ™è¢«ç§°ä¸º**å‡¹ (nonconvex)**å¤šè¾¹å½¢
- å¯¹è§’çº¿ (diagonal)ï¼šåœ¨ç®€å•å¤šè¾¹å½¢ä¸­ï¼Œè¿æ¥ä¸¤ä¸ªéè¿ç»­é¡¶ç‚¹çš„çº¿æ®µ
  - **å†…éƒ¨å¯¹è§’çº¿ (internal diagonal)**ï¼šå¦‚æœé™¤äº†ç«¯ç‚¹å¤–å®Œå…¨åœ¨å†…éƒ¨çš„å¯¹è§’çº¿

### 3. Well-ordering property 

* å‡è®¾ $râ‰¥d$ï¼Œå› ä¸º $a=dq_0+r$ï¼Œæ‰€ä»¥ $aâˆ’d(q_0+1)=râˆ’dâ‰¥0$ï¼Œå› æ­¤å­˜åœ¨ $q$ å’Œ $r$ï¼Œä½¿å¾— $0â‰¤r<d$ æˆç«‹ï¼ˆä¸” $q$ å’Œ $r$ æ˜¯å”¯ä¸€çš„ï¼‰

<img src="images/image-20250409103839783.png" alt="image-20250409103839783" style="zoom:67%;" />

## 5.3 Recursive Definition and Structural Induction

### 1. Recursively defined functions

*Recursively defined functions*, with <u>the set of nonnegative integers as its domain</u> :  

* **Basis Step**: Specify the value of the function at zero.
* **Recursive Step**: Give the rules for finding its value at an integer from its value at smaller integers

### 2. The Complexity of Euclidean algorithm

**LAMEâ€™S Theorem** Let $a , b$ be positive integers with $aâ‰¥b$. Then the number of divisions used by the Euclidean algorithm to find $gcd (a, b)$ is less than or equal to <u>five times the number of decimal digits in b</u>.

<img src="images/image-20250409135735686.png" alt="image-20250409135735686"  />

å› ä¸º b çš„åè¿›åˆ¶ä½æ•°ä¸º $âŒŠlogâ¡_{10}bâŒ‹+1â‰¤logâ¡_{10}b+1$ï¼Œç”±å®šç† 1 çŸ¥é™¤æ³•æ¬¡æ•°å°äºç­‰äº $5(logâ¡_{10}b+1)$ã€‚åˆå› ä¸º $5(log_{â¡10}b+1)$ æ˜¯ $O(logâ¡b)$ï¼Œå› æ­¤å¯ä»¥å¾—åˆ°ä¸Šè¿°ç»“è®ºã€‚

### 3. Recursively Defined Sets and Structures

**Sets can be defined recursively.** 

* ***BASIS STEP***: Specify an initial collection of elements. 
* ***RECURSIVE STEP***: Give the rules for constructing elements of the set from other  elements already in the set.

**Strings can be defined recursively.** 

- æ¥è‡ªå­—æ¯è¡¨ $Î£$ çš„å­—ç¬¦ä¸²ï¼Œæ˜¯ä¸€ä¸ªç”±æ¥è‡ª $Î£$ çš„ç¬¦å·æ„æˆçš„æœ‰é™åºåˆ—ã€‚

- æ¥è‡ªå­—æ¯è¡¨ $Î£$ çš„å­—ç¬¦ä¸²é›†åˆ $Î£^âˆ—$ï¼ŒæŒ‰ç…§ä¸‹é¢æ­¥éª¤é€’å½’å®šä¹‰ï¼š

  - ***BASIS STEP***ï¼š$Î»âˆˆÎ£^âˆ—$ï¼Œ$Î»$ æ˜¯ä¸åŒ…å«ç¬¦å·çš„ç©ºå­—ç¬¦ä¸²

  - ***RECURSIVE STEP***ï¼šå¦‚æœ$wâˆˆÎ£^âˆ—$ ä¸” $xâˆˆÎ£$ï¼Œé‚£ä¹ˆ$wxâˆˆÎ£^âˆ—$

    > åœ¨é€’å½’æ­¥éª¤ä¸­ï¼Œé€šè¿‡åœ¨åŸæœ‰å­—ç¬¦ä¸²çš„æœ«å°¾æ·»åŠ ä¸€ä¸ªå­—ç¬¦æ¥å½¢æˆæ–°çš„å­—ç¬¦ä¸²ã€‚

**String Concatenation**

>  **[Definition]**: Two strings can be combined via the operation of concatenation. Let $Î£$ be a set of symbols and $Î£^*$ be the set of strings formed from the symbols in $Î£$. We can define the  concatenation of two strings, denoted by **âˆ™**, recursively as follows. 

* ***BASIS STEP***: If $w âˆˆ Î£^*$, then $w âˆ™ Î»= w$
* **RECURSIVE STEP**: If  $w_1 âˆˆ Î£^*$ and $w_2 âˆˆ Î£$ and $x âˆˆ Î£$, then $w_1 âˆ™ (w_2 x)= (w_1 âˆ™w_2)x$.

Another important use of recursive definitions is to define well-formed formulae of various types.

**Well-formed formulae for compound propositions**

>  **[Definition]:**  The set of well-formed formulae in propositional logic involving **T**, **F**, propositional variables and operators from the set {$Â¬, âˆ§, âˆ¨, â†’, â†”$}

**Solution:**  

* **Basis Step:**  ***T**, **F***, and ***p*** where p is a propositional variable, are well-formed formulae.
* **Recursive Step:**  $(Â¬p)ï¼Œ(p âˆ¨ q)ï¼Œ(p âˆ§ q)ï¼Œ(p â†’ q)ï¼Œ(p â†” q)$, are well-formed formulae if p and q are well-formed formulae

### 4. Structural Induction

**A proof by structural induction ç»“æ„å½’çº³æ³•:**  

* **Basis Step:** Show that the result holds for all elements specified in the basis step of the recursive definition to be in the set.  
  <u>è¯æ˜ç»“æœå¯¹äºé€’å½’å®šä¹‰ä¸­åŸºç¡€æ­¥éª¤æ‰€æŒ‡å®šçš„æ‰€æœ‰å…ƒç´ éƒ½æˆç«‹ï¼Œè¿™äº›å…ƒç´ å±äºè¯¥é›†åˆã€‚</u>
* **Recursive Step:** Show that if the statement is true for each of the elements used to construct new elements in the recursive step of the definition, the result holds for these new elements.
  <u>è¯æ˜å¦‚æœè¯¥å‘½é¢˜å¯¹äºé€’å½’å®šä¹‰ä¸­ç”¨äºæ„é€ æ–°å…ƒç´ çš„æ¯ä¸ªå…ƒç´ éƒ½æˆç«‹ï¼Œé‚£ä¹ˆç»“æœå¯¹äºè¿™äº›æ–°å…ƒç´ ä¹Ÿæˆç«‹ã€‚</u>

**The validity of structural induction**

ä»¤ $P(n)$ è¡¨ç¤ºï¼šå¯¹äºæ‰€æœ‰ç”± $n$ æ¬¡æˆ–æ›´å°‘æ¬¡æ¥è‡ªé€’å½’å®šä¹‰ä¸­é€’å½’æ­¥éª¤çš„è§„åˆ™åº”ç”¨è€Œäº§ç”Ÿçš„å…ƒç´ ï¼Œç»“æœä¸ºçœŸ

- ***BASIS STEP***ï¼šè¯æ˜ $P(0)$ ä¸ºçœŸ
- ***RECURSIVE STEP***ï¼šå‡è®¾ $P(k)$ ä¸ºçœŸï¼Œé‚£ä¹ˆ $P(k+1)$ ä¸ºçœŸ

### 5. Generalized Induction

* **Generalized induction å¹¿ä¹‰å½’çº³æ³•** is used to prove results about sets other than the integers that  have the **well-ordering property**.

* Consider an ordering on $N â¨‰ N$, ordered pairs of nonnegative integers.  Specify that $(x_1 ,y_1)$ is less than or equal to $(x_2 ,y_2)$ if either $x_1 < x_2$, or $x_1 = x_2$  and $y_1<y_2$ .  This is called the ***lexicographic ordering*** ***è¯å…¸åº***

  ![image-20250409140908979](image-20250409140908979.png)

## 5.4 Recursive Algorithms

* An algorithm is called **recursive** if it solves a problem by <u>reducing it to an instance of the same problem with smaller input</u>.

### Recursion and Iteration 

* ***Recursion é€’å½’*** : Successively reducing the computation to the evaluation of the function an  smaller integers 
* ***Iteration è¿­ä»£*** : Start with the value of the function at one or more integers, the base cases, and successively apply the recursive definition to find the value of the  function at successive large integers

- å¯¹äºæ¯ä¸ªé€’å½’ç®—æ³•ï¼Œæ€»æœ‰ç­‰ä»·çš„è¿­ä»£ç®—æ³•
- **é€’å½’ç®—æ³•**ç›¸æ¯”è¿­ä»£ç®—æ³•ï¼Œé€šå¸¸*æ›´å°ã€æ›´ä¼˜é›…ã€æ›´æ˜“äºç†è§£*
- ç„¶è€Œï¼Œ**è¿­ä»£ç®—æ³•**åœ¨ç©ºé—´å’Œæ—¶é—´ä¸Šçš„æ•ˆç‡å¾€å¾€é«˜äºé€’å½’ç®—æ³•

# Ch6 Counting

## 6.1 The Basics of Counting

* **The Product Rule ä¹˜ç§¯æ³•åˆ™** : Suppose that a procedure can be broken down into two tasks. If there are $n_1$ ways to do the first task and $n_2$ ways to do the second after the first task has been done, then there are $n_1 n_2$ ways to complete the procedure. 

  ***Product Rule in Terms of Sets*** : If $A_1, A_2, â€¦ , A_m$ ainite sets, then the number of elements in the Cartesian product of these sets is the product of the number of elements of each set

  * $|A_1 â¨‰ A_2 â¨‰ \dots â¨‰ A_m |= |A_1| \times |A_2| \times \dots\times|A_m|$

* **The Sum Rule åŠ æ³•æ³•åˆ™** :  $|A_1 âˆª A_2 âˆª \dots âˆª A_m |= |A_1| + |A_2| + \dots + |A_m| , when \space A_i âˆ© A_j  = \empty \space for \space all \space i,\space j$

* **The Subtraction Rule å‡æ³•æ³•åˆ™** : å®¹æ–¥åŸç†(the inclusion-exclusion principle)If S and T are finite sets, then $âˆ£SâˆªTâˆ£=âˆ£Sâˆ£+âˆ£Tâˆ£âˆ’âˆ£Sâˆ©Tâˆ£$

* **The Division Rule é™¤æ³•æ³•åˆ™** : There are $n/d$ ways to do a task if it can be done using a procedure that can be carried out in $n$ ways, and for every way $w$, exactly $d$ of the $n$ ways correspond to way $w$. 

* **Tree Diagrams** : We can solve many counting problems through the use of tree diagrams, where a branch represents a possible choice and the leaves represent possible outcomes. 

## 6.2 The Pigeonhole Principle

[ Theorem 1 ] ***The Pigeonhole Principle*** 
If $k$ is a positive integer and $k+1$ or more objects are placed into $k$ boxes, then there is at least one box containing two or more of the objects. 

> é¸½å·¢åŸç†åˆè¢«ç§°ä¸ºç‹„åˆ©å…‹é›·æŠ½å±‰åŸç† (*Dirchlet drawer principle*)

![image](image.png)

[Theorem 2] ***The Generalized Pigeonhole Principle*** 
If $N$ objects are placed into $k$ boxes, then there is at least one box containing at least $âŒˆN/kâŒ‰$ objects.

## 6.3 Permutations and Combinations
### 1. Permutation æ’åˆ—
* ***permutation*** : an **ordered** arrangement of the elements of a set
* ***r-permutation*** : an **ordered** arrangement of $r$ elements of a set

ã€Theorem 1ã€‘ The number of **r-permutations** of a set with $n$ distinct elements is $P(n, r)=n(n-1)(n-2)â€¦(n-r+1)= n!/(n-r)!$
### 2. Combination ç»„åˆ
* **r-combination**: an **unordered** selection of $r$ elements of a set 

Note: An $r$-combination is simply a subset of a set with $r$ elements.

$C(n, r)$: the number of $r$-combination of a set with $n$ element 

ã€Theorem 2ã€‘ The number of $r$-combination of a set with $n$ elements, where $n$ is a positive integer and $r$ is an integer with $0â‰¤râ‰¤n$, equals $n(n-1)(n-2)â€¦(n-r+1)/r! = n!/r!(n-r)!$

ã€Corollaryã€‘Combination Corollary: Let $n$ and $r$ be nonnegative integers with $r â‰¤ n$. Then $C(nï¼Œr)= C(nï¼Œn-r)$

* A combinatorial proof of an identity:
  * **double counting proofs** : uses counting arguments to prove that both sides of the identity count the same objects but in different ways.
  * **bijective proofs** : show that there is a bijection between the sets of objects counted by the two sides of the identity.

##  6.4 Binomial Coefficients

[ Definition ] : A ***binomial expression äºŒé¡¹è¡¨è¾¾å¼*** is the sum of two terms, such as $x + y$. (More generally, these terms can be products of constants and variables)

* ã€Theorem 1ã€‘***The Binomial Theorem äºŒé¡¹å¼å®šç†*** : Let $x$ and $y$ be varaibles, and let $n$ be a nonnegative integer. Then $(x+y)^n = \sum_{j = 0}^{n} \binom{n}{j}x^{n-j}y^{j}$
$$
\begin{align*}
(x + y)^n&=\sum_{j = 0}^{n} \binom{n}{j}x^{n - j}y^{j}\\
&=\binom{n}{0}x^{n}+\binom{n}{1}x^{n - 1}y+\cdots+\binom{n}{n - 1}xy^{n - 1}+\binom{n}{n}y^{n}
\end{align*}
$$

* ã€Theorem 2ã€‘ ***PASCALâ€™S Identity å¸•æ–¯å¡æ’ç­‰å¼*** : Let $n$ and $k$ be positive integers with $k â‰¤ n$. Then 
  $$
  \binom{n+1}{k}=\binom{n}{k-1} + \binom{n}{k}
  $$
  
* ã€Theorem 3ã€‘ ***Vandermondeâ€™s Identity èŒƒå¾·è’™å¾·æ’ç­‰å¼*** : Let $m$, $n$ and $r$ be nonnegative integer with $r$ not exceeding either $m$ or $n$. Then 
  $$
  \binom{n+m}{r}=\sum_{k=0}^r\binom{n}{k}  \binom{m}{r-k}
  $$
  

  * ã€Corollaryã€‘If $n$ is a nonnegative integer. Then 
    $$
    \binom{2n}{n}=\sum_{k=0}^n\binom{n}{k}^2
    $$
    

* ã€Theorem 4ã€‘Let $n$ and $r$ be nonnegative integer with $râ‰¤n$. Then 
  $$
  \binom{n+1}{r+1}=\sum_{j=r}^n\binom{r}{j}
  $$
  

## 6.5 Generalized Permutations and Combinations
### 1. Permutations With Repetition
* ##### ã€Theorem 1ã€‘The number of r-permutations of a set of n objects with repetition allowed is $n^r$.
  
   å¯¹åŒ…å« $n$ ç±»å¯¹è±¡çš„é›†åˆè¿›è¡Œ $r$ æ’åˆ—ï¼Œå¦‚æœå…è®¸é‡å¤ï¼Œåˆ™æ€»æ•°ä¸º $n^r$

### 2. Combination With Repetition

* ##### ã€Theorem 2ã€‘There are ==$C (n-1+r, r)$== r-combination from a set with $n$ elements when repetition of elements is allowed.
  
  å¯¹åŒ…å« $n$ ç±»å¯¹è±¡çš„é›†åˆè¿›è¡Œ $r$ ç»„åˆï¼Œå¦‚æœå…è®¸é‡å¤ï¼Œåˆ™æ€»æ•°$C(nâˆ’1+r,r)=C(nâˆ’1+r,nâˆ’1)$ï¼Œè®°ä½œ ==$H_{n}^{r}$==
  
  > å³ $r$ ä¸ªä¸å¯åŒºåˆ†çš„ç‰©ä½“æ”¾å…¥ $n$ ä¸ªå¯åŒºåˆ†çš„ç®±å­ä¸­, å…± $H_n^r=C_{n-1+r}^r$ ç§æƒ…å†µ

<img src="images/image-20250416130507966.png" alt="image-20250416130507966" style="zoom:80%;" />

### Permutations of Sets With Indistinguishable Objects
n-Permutation with limited repetition $A = { n_{1â€¢} a_1 ,n_{2 â€¢} a_2 ,â€¦,n_{k â€¢} a_k } ï¼Œwhere n_1 +n_2 +â€¦+n_k = n$

* ##### ã€Theorem 3ã€‘ The number of different permutations of $n$ objects, where there are $n_1$ indistinguishable objects of type1,â€¦,and $n_k$ indistinguishable objects of type k, is  ==$\frac{n!}{n_1! n_2! \ldots n_k!}$==
  
  å¯¹ $n$ ä¸ªç‰©ä½“è¿›è¡Œæ’åˆ—ï¼Œå…¶ä¸­æœ‰ $n_i$ ä¸ªå±äºç±»å‹ $i$ çš„ç‰©ä½“$(i=1,2,\dots,n)$ï¼Œåˆ™æ’åˆ—ç§æ•°ä¸º$\frac{n!}{n_1! n_2! \ldots n_k!}$
  
  <img src="images/image-20250416131025490.png" alt="image-20250416131025490" style="zoom:130%;" />

### 3. Distributing objects into boxes
#### 3.1 Distinguishable Objects and Distinguishable Boxes
ã€Theorem 4ã€‘The number of ways to distribute $n$ distinguishable objects into $k$ distinguishable boxes so that $n_i$ objects are place into box $i$, $i=1,2,â€¦,k$, equals ==$\frac{n!}{n_1 !n_2 !â€¦n_k!}$==
*å°† $n$ ä¸ªå¯åŒºåˆ«çš„ç‰©ä½“æ”¾å…¥ $k$ ä¸ªå¯åŒºåˆ†çš„ç®±å­ä¸­ï¼Œ$n_i$ è¡¨ç¤ºç¬¬ $i$ä¸ªç®±å­ä¸­ç‰©ä½“çš„æ•°é‡*

#### 3.2 Indistinguishable Objects and Distinguishable Boxes
There are ==$C(n  âˆ’ 1+k, k)$== ways to place $k$ indistinguishable objects into $n$ distinguishable boxes.
*å°†  $r$ ä¸ªä¸å¯åŒºåˆ†çš„ç‰©ä½“æ”¾å…¥ $n$ ä¸ªå¯åŒºåˆ†çš„ç®±å­*

#### 3.3 Distinguishable Objects and Indistinguishable Boxes 
counting the ways to place $n$ distinguishable objects into $k$ indistinguishable boxes
 *å°† $n$ ä¸ªå¯åŒºåˆ†ç‰©ä½“æ”¾å…¥ $j$ ä¸ªä¸å¯åŒºåˆ†çš„ç®±å­*

***Stirling numbers of the second kind ç¬¬äºŒç±»æ–¯ç‰¹æ—æ•°***

* the number of ways to distribute $n$ **distinguishable objects** into $j$ **indistinguishable boxes** so that no boxes is empty. 

* **Notation:  ==$S(n,j)$==** â€”â€”<u>å°† $n$ ä¸ªå¯åŒºåˆ†ç‰©ä½“æ”¾å…¥ $j$ ä¸ªä¸å¯åŒºåˆ†çš„ç®±å­ï¼Œä¸”æ¯ä¸ªç®±å­**éç©º**çš„æ–¹æ³•æ•°</u>
  
  * $S(r,1)=S(r,r) = 1$
  * $S(r,2) = 2^{r-1}-1$
  * $S(r,r-1)=S(r,2)$
  * $S(r+1,n) = S(r,n-1)+nS(r,n)$
  
* åˆ©ç”¨å®¹æ–¥åŸç†ï¼Œå¯å¾—
  $$
  S(n,j) =  \frac{1}{j!} \sum ^{j} _{i=0}(-1)^i \binom{j}{i}(j-i)^n
  $$
  

  å› æ­¤ï¼Œå°† $n$ ä¸ªå¯åŒºåˆ†ç‰©ä½“æ”¾å…¥ $k$ ä¸ªä¸å¯åŒºåˆ†çš„ç®±å­çš„æ–¹æ³•æ•°ä¸º
  $$
  \sum ^k _{j=1} S(n,j) = \sum ^k _{j=1} \frac{1}{j!} \sum ^{j} _{i=0}(-1)^i \binom{j}{i}(j-i)^n
  $$
  

#### 3.4 Indistinguishable Objects and Indistinguishable Boxes

>æ³¨ï¼šæ²¡æœ‰é—­åˆå…¬å¼èƒ½å¤Ÿæ±‚è§£è¿™ç±»é—®é¢˜

#### Note:
1. $S(n, j)$ is the number of ways to partition the set with $n$ elements into $j$ nonempty and disjoint subsets.
2. $S(n, j)j!$ is the number of ways to distribute $n$ distinguishable objects into $j$ distinguishable boxes so that no boxes is empty 
  *  the number of onto functions from a set with $n$ elements to a set with $j$ elements
    $S(n, j)j! = \left(\sum_{i = 0}^{j - 1} (-1)^i C_j^i (j - i)^n\right)$
3. the number of ways to place $n$ distinguishable objects into $k$ indistinguishable boxes
    $\sum_{j = 1}^{k} S(n, j)=\sum_{j = 1}^{k} \left(\left(\sum_{i = 0}^{j - 1} (-1)^i C_j^i (j - i)^n\right)/j!\right)$

# Ch8 Advanced Counting Techniques

## 8.1 Applications of Recurrence Relations

### Recurrence Relations

**[Definition]** A recurrence relation for the sequence $\{a_n \}$ is an equation that express $a_n$ in terms of one or more of the previous terms of the sequence, namely, $a_0,a_1,\dots,a_{n-1}$, for all integers $ n$ with $nâ‰¥n_0$, where $n_0$ is a nonnegative integers. $a_n  = f  (  a_0  ,  a_1  ,  a_2  ,  â€¦ , a_{n-1}  )   \space nâ‰¥n_0$

* **A solution of a recurrence relation** is a **sequence** if its terms satisfy the recurrence relation.

* The **degree** of a recurrence relation  
  * $a_n = a_{n-1}  + a_{n-8}$   â€” a recurrence relation of degree $8$

### Algorithm and Recurrence relations

* Dynamic programming algorithm
* Divide-and-conquer algorithm

## 8.2 Solving Linear Recurrence Relations

### 1. Linear Homogeneous Recurrence Relations 

> çº¿æ€§é½æ¬¡é€’æ¨å…³ç³»

***k é˜¶å¸¸ç³»æ•°çº¿æ€§é½æ¬¡é€’æ¨å…³ç³» (linear homogeneous recurrence relation of degree k with constant coefficient)***
$a_n=c_1a_{nâˆ’1}+c_2a_{nâˆ’2}+\dots+c_ka_{nâˆ’k}$ where $c_1 , c_2 ,\dots, c_k$  are real numbers, and $c_k  â‰ 0$

- ***linear çº¿æ€§***ï¼šç­‰å·å³è¾¹æ˜¯åºåˆ—ä¸­å‰å‡ é¡¹ä¸å¸¸ç³»æ•°ä¹‹ç§¯çš„å’Œ
- ***homogeneous é½æ¬¡***ï¼šæ¯é¡¹æ¬¡æ•°ä¸è¶…è¿‡ 1
- ***constant å¸¸æ•°***ï¼šåºåˆ—ä¸­çš„æ¯ä¸€é¡¹ç³»æ•°éƒ½æ˜¯å¸¸æ•°ï¼Œè€Œéå…³äº $n$ çš„å‡½æ•°
- ***degree ké˜¶***ï¼š$a_n$ æ˜¯ç”±åºåˆ—ä¸­çš„å‰$k$é¡¹è¡¨è¾¾çš„

### 2. Solving Linear Homogeneous Recurrence Relation With Constant Coefficients 

> æ±‚è§£å¸¸ç³»æ•°çº¿æ€§é½æ¬¡é€’æ¨å…³ç³»

#### 2.1 **Two key ideas to find all their solutions:**

1. **These recurrence relations have solutions of the form $a_n = r_n$, where $r$ is a constant**
   è¿™ç§é€’æ¨å…³ç³»æœ‰å½¢å¦‚ ==$a_n=r^n$== çš„è§£ï¼Œ$r$ ä¸ºå¸¸æ•°ã€‚

$$
\begin{align}
    r^n-c_1r^{n-1}-c_2r^{n-2}-\dots--c_kr^{n-k}=0\\
    r^{n-k}(r^k-c_1r^{k-1}-c_2r^{k-2}-\dots--c_k)=0\\
    r^k-c_1r^{k-1}-c_2r^{k-2}-\dots--c_k=0
    \end{align}
$$
* The sequence $\{a_n\}$ with $a_n = r_n$ where $r â‰  0$ is a solution if and only if $r$ is a solution of this last equation.

  > æˆ‘ä»¬ç§°ä¸Šè¿°æ–¹ç¨‹ä¸º**ç‰¹å¾æ–¹ç¨‹ (characteristic equation)**ï¼Œç§°è¿™ä¸ªæ–¹ç¨‹çš„è§£ä¸º**ç‰¹å¾æ ¹ (characteristic roots)**

2. **A linear combination of two solutions of a linear homogeneous recurrence relation is also a solution.** 

* suppose that $s_n$ and $t_n$ are both solutions of this recurrence relation. Then
  çº¿æ€§é½æ¬¡é€’æ¨å…³ç³»çš„ä¸¤ä¸ªè§£çš„**çº¿æ€§ç»„åˆ**ä¹Ÿæ˜¯å®ƒçš„è§£
$$
  s_n=c_1s_{n-1}+c_2s_{n-2}+\dots+c_ks_{n-k}\\
  t_n=c_1t_{n-1}+c_2t_{n-2}+\dots+c_kt_{n-k}\\
$$
   Now suppose that $b_1$ and $b_2$ are real numbers. Then
$$
  b_1s_n+b_2t_n=c_1(b_1s_{n-1}+b_2t_{n-1})+c_2(b_1s_{n-2}+b_2t_{n-2})+\dots+c_k(b_1s_{n-k}+b_2t_{n-k})
$$
This means that ==$b_1 s_n + b_2 t_n$== is also a **solution** of the same linear homogeneous recurrence relation. 

#### 2.2 The Degree Two Case

* **[ Theorem 1 ]** 
  Let $c_,c_2$ be real numbers. Suppose that $r^2-c_1r-c_2=0$ has ***<u>two distinct roots</u>*** $r_1,r_2$. Then the sequence $\{a_n\}$ is a solution of the recurrence relation $a_n=c_1a_{n-1}+c_2a_{n-2}$ if and only if ==$a_n=\alpha_1r_1^n+\alpha_2r_2^n $==$\space for \space n=0,1,2,\dots$ where $\alpha_1,\alpha_2$ are constants. 

* **[ Theorem 2 ]**
   Let $ c_1, c_2 $ be real numbers with $ c_2 \neq 0 $. Suppose that $ r^2 - c_1 r - c_2 = 0 $ has ***<u>only one root</u>*** $r_0 $. A sequence $\{a_n\} $ is a solution of the recurrence relation $a_n = c_1 a_{n-1} + c_2 a_{n-2} $ if and only if ==$a_n = (\alpha_1 + \alpha_2 n )r_0^n $==$\text{ for } n = 0, 1, 2, \ldots, $ where $\alpha_1, \alpha_2 $ are constants.

#### 2.The General Case

* **[ Theorem 3 ]**
  Let $c_1, c_2, \ldots, c_k$ be real numbers. Suppose that the characteristic equation $r^k - c_1 r^{k-1} - \ldots - c_k = 0$ has $k$ ***<u>distinct roots</u>*** $r_1, r_2, \ldots, r_k$. Then a sequence $\{a_n\}$ is a solution of the recurrence relation
  $a_n = c_1 a_{n-1} + c_2 a_{n-2} + \ldots + c_k a_{n-k}$ if and only if ==$a_n = \alpha_1 r_1^n + \alpha_2 r_2^n + \ldots + \alpha_k r_k^n$== for $n = 0, 1, 2, \ldots$, where $\alpha_1, \alpha_2, \ldots, \alpha_k$ are constants.

* **[ Theorem 4 ]**
  Let $c_1, c_2, \ldots, c_k$ be real numbers. Suppose that the characteristic equation $r^k - c_1 r^{k-1} - \ldots - c_k = 0$ has ***<u>t distinct roots tä¸ªä¸åŒçš„æ ¹</u>*** $r_1, r_2, \ldots, r_t$ with ***<u>multiplicitiesé‡æ•°</u>*** $m_1, m_2, \ldots, m_t$, respectively, so that $m_i \geq 1$ for $i = 1, 2, \ldots, t$ and $m_1 + m_2 + \ldots + m_t = k$. Then a sequence $\{a_n\}$ is a solution of the recurrence relation $a_n = c_1 a_{n-1} + c_2 a_{n-2} + \ldots + c_k a_{n-k}$ if and only if
$$
\begin{aligned}
a_n = & \left( \alpha_{1,0} + \alpha_{1,1} n + \cdots + \alpha_{1,m_1-1} n^{m_1-1} \right) r_1^n \\
& + \left( \alpha_{2,0} + \alpha_{2,1} n + \cdots + \alpha_{2,m_2-1} n^{m_2-1} \right) r_2^n \\
& + \cdots + \left( \alpha_{t,0} + \alpha_{t,1} n + \cdots + \alpha_{t,m_t-1} n^{m_t-1} \right) r_t^n
\end{aligned}
$$
â€‹       for $n = 0, 1, 2, \ldots$ where $\alpha_{i,j}$ are constants for $1 \leq i \leq t, 0 \leq j \leq m_i - 1$.

### 3. Linear Nonhomogeneous Recurrence Relation With Constant Coefficients 

> å¸¸ç³»æ•°çº¿æ€§éé½æ¬¡é€’æ¨å…³ç³»

***k é˜¶å¸¸ç³»æ•°çº¿æ€§éé½æ¬¡é€’æ¨å…³ç³» (linear nonhomogeneous recurrence relation of degree k with constant coefficient)***ï¼š
$a_n=c_1a_{nâˆ’1}+c_2a_{nâˆ’2}+\dots+c_ka_{nâˆ’k}+F(n)$ where $c_1 , c_2 ,\dots, c_k$  are real numbers, $F(n)$ is a **function** not  identically zero depending only on $n$
$a_n=c_1a_{nâˆ’1}+c_2a_{nâˆ’2}+\dots+c_ka_{nâˆ’k}$ is called ***å…³è”é½æ¬¡é€’æ¨å…³ç³» (associated homogeneous recurrence relation)***

**[ Theorem 5 ]**

* Let $\{a_n^{(p)}\}$ be ***a particular solution ç‰¹æ®Šè§£*** of <u>the nonhomogeneous linear</u> recurrence relation with constant coefficients

$$
a_n = c_1 a_{n-1} + c_2 a_{n-2} + \ldots + c_k a_{n-k} + F(n)
$$
Then every solution is of the form ==$\{a_n^{(p)} + a_n^{(h)}\}$==, where $\{a_n^{(h)}\}$ is **a solution** of <u>the associated homogeneous recurrence relation</u>.

> è™½ç„¶æ²¡æœ‰é€šæ³•æ¥æ‰¾åˆ°å…³äºä»»æ„å‡½æ•° $F(n)$ çš„è§£ï¼Œä½†æ˜¯å¯¹äºæŸäº›ç±»å‹çš„å‡½æ•°ï¼Œæ¯”å¦‚å¤šé¡¹å¼æˆ–è€…å¸¸æ•°å¹‚ï¼Œæ˜¯æœ‰åŠæ³•å¯ä»¥è§£å†³çš„ï¼Œå¦‚<u>å®šç†6</u>

**[ Theorem 6 ]**

* Assume ***a linear nonhomogeneous recurrence equation with constant coefficients*** with the nonlinear part $F(n)$ of the form
  * The solution is ==$F(n) = (b_t n^t + b_{t-1} n^{t-1} + \ldots + b_1 n + b_0) s^n$==

1. If $s$ is **not** a root of the characteristic equation of the associated homogeneous recurrence equation, there is a particular solution of the form
   ( $s$ä¸æ˜¯å…³è”é½æ¬¡é€’æ¨å…³ç³»çš„ç‰¹å¾æ–¹ç¨‹çš„æ ¹ )
   * The solution is ==$(p_t n^t + p_{t-1} n^{t-1} + \dots + p_1 n + p_0) s^n$==

2. If $s$ is **<u>a root of multiplicity $m$</u>**, a particular solution is of the form
   ( $s$æ˜¯å…³è”é½æ¬¡é€’æ¨å…³ç³»çš„ç‰¹å¾æ–¹ç¨‹çš„æ ¹ï¼Œé‡æ•°ä¸º$m$ )
   * The solution is ==$n^m (p_t n^t + p_{t-1} n^{t-1} + \dots + p_1 n + p_0) s^n$==

## 8.4 Generating Functions

**[ Definition ]** The ***generating functionç”Ÿæˆå‡½æ•°*** for the sequence $a_1,a_2,\dots,a_k,\dots$ of real numbers is the ***infinite seriesæ— é™çº§æ•°***.
$$
G(x)=a_0+a_1x+a_2x^2+\dots+a_kx^k+\dots=\sum_{k=0}^{\infty}a_kx^k
$$

* The generating function for ***finite*** sequence of real numbers $a_0,a_1,a_2,\dots,a_n$ is 
  $$
  G(x)=a_0+a_1x+a_2x^2+\dots+a_nx^n
  $$

### Useful Facts About Power Series

* **[ Theorem 1 ]** Let $f(x)=\sum_{k=0}^{\infty}a_k x^k, g(x)=\sum_{k=0}^{\infty}b_k x^k$. Then
  1.  $$ f(x)+g(x)=\sum_{k = 0}^{\infty}(a_{k}+b_{k})x^{k}  $$
  2. $$ \alpha\cdot f(x)=\sum_{k = 0}^{\infty}\alpha\cdot a_{k}x^{k}\quad \alpha\in R $$
  3.  $$ x\cdot f^{\prime}(x)=\sum_{k = 0}^{\infty}k\cdot a_{k}x^{k} $$
  4. $$ f(\alpha x)=\sum_{k = 0}^{\infty}\alpha^{k}\cdot a_{k}x^{k} $$ 
  5. $$ f(x)g(x)=\sum_{k = 0}^{\infty}(\sum_{j = 0}^{k}a_{j}b_{k - j})x^{k} $$ 

#### **The extended binomial coefficient**

Recall $\binom{m}{k}=C(m,k)= \frac{m!}{k!(m-k)!}$

**[ Definition ]** Let $u$ be a real number and $k$ a nonnegative integer. Then the ***extended binomial coefficientæ‰©å±•äºŒé¡¹å¼ç³»æ•°*** is defined by $$ \begin{pmatrix} u \\ k \end{pmatrix}= \begin{cases} u(u - 1)\cdots(u - k + 1)/k! &\text{if } k > 0 \\ 1 &\text{if } k = 0 \end{cases} $$ 

* If $n > 0$, then $\binom{-n}{r}=(-1)^r\binom{n+r-1}{r}=(-1)^rC(n+r-1,r)$

#### **The extended Binomial Theorem**

**[ Theorem 2 ]** Let $x$ be a real number with $|x|<1$ and let $u$ be a real number. Then 
$$
(1+x)^u=\sum_{k=0}^{\infty}\binom{u}{k}x^k
$$
![image-20250423201104412](image-20250423201104412.png)

### Counting Problems and Generating Functions

<img src="images/image-20250423201325630.png" alt="image-20250423201325630" style="zoom:80%;" />

### Use Generating Function To Solve Recurrence Relations



<img src="images/image-20250423201416355.png" alt="image-20250423201416355" style="zoom:80%;" />

### Proving Identities Via Generating Functions

>  ç•¥

## 8.5 Inclusion-Exclusion and Its Application

### The Principle of inclusion-exclusion

> å®¹æ–¥åŸç†

The formula for the number of elements in the union of $n$ finite sets:
$$
\left|A_1\cup A_2\cup\cdots\cup A_n\right| = \sum_{i = 1}^{n}\left|A_i\right| - \sum_{1\leq i < j\leq n}\left|A_i\cap A_j\right| + \sum_{1\leq i < j < k\leq n}\left|A_i\cap A_j\cap A_k\right|+\cdots+(- 1)^{n - 1}\left|A_1\cap A_2\cap\cdots\cap A_n\right|
$$


*  There are $2^n âˆ’ 1$ terms in this formula

## 8.6 Applications of Inclusion-Exclusion

### An alternative form of inclusion-exclusion

* To solve problems that ask for the number of elements in a set that have none of n properties.

  $$P_1,P_2,\dots,P_n$$

  Let $A_i$ be the subset containing the elements that have property $P_i$.

  $N(P_1,P_2,\dots,P_k)$ : The number of elements with all properties $P_1,P_2,\dots,P_k$

  It follows that $N(P_1,P_2,\dots,P_k)= \left|A_1\cap A_2\cap\cdots\cap A_k\right|$

  $N(P_1^{'},P_2^{'},\dots,P_k^{'})$ : The number of elements with none properties $P_1,P_2,\dots,P_k$

  From the inclusion-exclusion principle, we see that
  $$
  N(P_1^{'},P_2^{'},\dots,P_n^{'})=N-\sum_{1 \leq i \leq n}N(P_i)+\sum_{1 \leq i < j \leq n}N(P_i P_j)+\dots+(-1)^n N(P_1P_2\dots P_n)
  $$

### The number of onto functions

**Theorem**: Let $m$ and $n$ be positive integers with $m\geq n$. Then, there are  $n^m - C(n, 1)(n - 1)^m + C(n, 2)(n - 2)^m-\cdots+(-1)^{n - 1}C(n, n - 1)\cdot1^m$ **onto functions** from a set with $m$ elements to a set with $n$ elements. 

### Derangements

> å…¨é”™ä½æ’åˆ—

*  A derangement is a permutation of objects that leaves no object in the original position.

**Theorem**: The number of derangements of a set with $n$ elements is
$$
D_n=n![1-\frac{1}{1!}+\frac{1}{2!}+\dots+(-1)^n\frac{1}{n!}]
\\(NOTE:D_n=D_{n-1}+D_{n-2})
$$

# Ch9 Relations

## 9.1 Relations and Their Properties

### 1. Functions as Relations

* **Binary relation**

  **[Definition] ** A **binary relationäºŒå…ƒå…³ç³»** $R$ from a set $A$ to a set $B$ is a subset of $AÃ—B$.

  **Note** :

  * A binary relation $R$ is a set
  * $R \subseteq A\times B$
  * $R = \{(a,b)|a \in A,b \in B, aRb \}$

 Relations are a ***generalizationæ³›åŒ–*** of function.

### 2. Relations On A Set

**[Definition]** A relation on the set $A$ is a **relation** form $A$ to $A$

* $R \subseteq A\times A$

* A set $A$ with $n$ elements has $2^{n^2}$ binary relations

### 3. Properties of Binary Relations

#### 3.1 Reflexive Relations

**ã€Definitionã€‘**A relation $R$ on a set $A$ is ***reflexiveè‡ªåæ€§*** if $(x,x)\in R,\text{for every element }x\in A $, $\forall x (x\in A\rightarrow (x, x)\in R)$

* All the elements on the ***main diagonalä¸»å¯¹è§’çº¿*** of a matrices must be **1s**
* There is a ***loopç¯*** at every vertex of the directed graph

**ã€Definitionã€‘** A relation $R$ on a set $A$ is ***irreflexiveéè‡ªåæ€§*** if $\forall x (x\in A\rightarrow (x, x)\notin R)$

* All the elements on the ***main diagonalä¸»å¯¹è§’çº¿*** of a matrices must be **0s**

#### 3.2 Symmetric Relations

**ã€Definitionã€‘**A relation $R$ on a set $A$ is ***symmetricå¯¹ç§°æ€§*** if $\forall x \forall y ((x,y)\in R\rightarrow (y, x)\in R)$

> $(a,b)=(b,a)$ æ’æˆç«‹

**ã€Definitionã€‘**A relation $R$ on a set $A$ is ***antisymmetric åå¯¹ç§°æ€§*** if $\forall x \forall y ((x,y)\in R \and (y,x)\in R\rightarrow x=y)$

**ã€Definitionã€‘**A relation $R$ on a set $A$ is ***asymmetric ä¸å¯¹ç§°æ€§*** if $\forall x \forall y ((x,y)\in R \rightarrow (y,x)\notin R)$

> - å¯¹ç§°æ€§å’Œåå¯¹ç§°æ€§ä¸æ˜¯å¯¹ç«‹çš„ï¼Œä¸€ä¸ªå…³ç³»å¯èƒ½åŒæ—¶å…·æœ‰å¯¹ç§°æ€§å’Œåå¯¹ç§°æ€§

#### 3.3 Transitive Relations

**ã€Definitionã€‘**A relation $R$ on a set $A$ is ***transitiveä¼ é€’æ€§*** if  $\forall x \forall y \forall z (  (x,y)\in R \and (y,z)\in R \rightarrow (x,z) \in R  )$

* $\overline{(m_{ij} \and m_{jk})} \or m_{ik} = 1$
* If there is an arc from $x$ to $y$ and one from $y$ to $z$ then there  must be one from $x$ to $z$.  

### 4. Combining Relations

Since relations form $A$ to $B$ are subsets of $AÃ—B$, two relations form $A$ to $B$ can be combined in any way two sets can be combined (Set operation $\cup, \cap, -,âŠ•$).  

#### Compositionå¤åˆ 

Let $R=\{(a,b)|a \in A, b \in B, aRb\}$ , $ S=\{ (b,c)|b\in B, c \in C,bSc \}$,

Then $Sâˆ˜R=\{ (a,c)|a \in A \and c \in C \and \exist b (b \in B \and aRb \and bSc) \}$

* Note : $Sâˆ˜R \neq Râˆ˜S$

#### Inverse relation

$R=\{(a,b)|a\in A,b \in B, aRb\}$

 The inverse relation form B to A : $R^{-1}(R^c)=\{ (b,a)|(a,b)\in R,a \in A, b \in B \}$

#### The properties of relation operations 

Suppose that $R, S$ are the relations from $A$ to $B$, $T$ is the relation from $B$ to $C$, $P$ is the relation from $C$ to $D$, then

1.  $(R\cup S)^{-1} = R^{-1}\cup S^{-1}$
2.  $(R\cap S)^{-1} = R^{-1}\cap S^{-1}$
3.  $(\overline{R})^{-1}=\overline{R^{-1}}$
4.  $(R- S)^{-1} = R^{-1}- S^{-1}$
5.  $(A\times B)^{-1} = B \times A$
6.  $\overline{R}=A\times B-R$
7.  $(Sâˆ˜T)^{-1}=T^{-1}âˆ˜S^{-1}$
8.  $(Râˆ˜T)âˆ˜P=Râˆ˜(Tâˆ˜P)$
9.  $(R\cup S)âˆ˜T=Râˆ˜T\cup Sâˆ˜T$

#### The Power of a relation R

ã€Definitionã€‘Let $R$ be a relation on the set $A$. The powers $R^n , n=1,2,3, \dots$  are defined inductively by $R^1=R$ and $R^{n+1}=R^nâˆ˜R$

ã€Theoremã€‘The relation $R$ on a set $A$ is **transitive** if and only if $R^n \subseteq R, for\space n=1,2,\dots$

* If $R$ is reflexive, then $R^n$ is reflexive
* If $R$ is symmetric, then $R^n$ is symmetric

## 9.2 **n-ary Relations**

**[ Definition ] ** Let $A_1,A_2,\dots,A_n$ be sets, An ***n-ary relation*** on these sets is a subset of $A_1Ã—A_2Ã—\dots Ã—A_n$.

## 9.3 Representing Relations 

**The methods of representing relation**:  

* list its all ordered pairs 
* using a set build notation/specification by predicates  
* 2D table 
* Connection matrix /zero-one matrix 
* Directed graph/Digraph

### 1. Connection Matrices

**[ Definition ]** : Let $R$ be a relation from $A = \{a_1,a_2,\dots,a_m\}$, to $B=\{b_1, b_2, \dots b_n\}$, 
An $m \times n$ ***connection matrixè¿æ¥çŸ©é˜µ*** $M_R=[m_{ij}]$ for $R$ is defined by
$$
m_{ij}= \begin{cases} 1 & \text{if } (a_i, b_j)\in R, \\ 0 & \text{if } (a_i, b_j)\notin R. \end{cases}
$$

### 2. Directed graph/Digraph

**[ Definition ]** A ***directed graph*** or a ***digraph***, consists of a set $V$ of vertices together with a set $E$ of ordered pairs of elements of $V$ called ***edges(or arcs)***. The ***vertices*** $a,b$ is called the **initial** and **terminal** vertices of the edge $(a,b)$.

## 9.4 Closures of Relations 

**ã€Definitionã€‘**The ***closureé—­åŒ…*** of a relation $R$ with respect to property $P$ is the relation $S$ with property $P$
containing $R$ such that $S$ is a subset of every relation with property $P$ containing $R$.

å¦‚æœ $R$ æ˜¯åœ¨é›†åˆ $A$ä¸Šçš„å…³ç³»ï¼Œé‚£ä¹ˆ $R$ å…³äºæ€§è´¨ $P$ çš„**é—­åŒ… (closure)**ï¼Œå®ƒæ»¡è¶³æ€§è´¨ $P$ ä¸”åŒ…æ‹¬ $R$ï¼Œè€Œä¸”æ˜¯æ‰€æœ‰åŒ…å« $R$ ä¸”æ»¡è¶³ $P$ çš„ $AÃ—A$ çš„å­é›†

> The smallest relation with property $P$ containing $R $

### 1. Reflexive Closure

**ã€Theoremã€‘**Let $R$ be a relation on $A$. The ***reflexive closureè‡ªåé—­åŒ…*** of $R$, denoted by $r(R)$, is $R\cup I_A$(The ***diagonal relationå¯¹è§’å…³ç³»*** on A, $I_A=\{ (x,x)|x\in A\}$).

**ã€Corollaryã€‘**$R=R\cup I_A$ â‡” $R$ is a reflexive relation

### 2. Symmetric Closure

**ã€Theoremã€‘**Let $R$ be a relation on $A$. The ***symmetric closureå¯¹ç§°é—­åŒ…*** of $R$, denoted by $r(R)$, is $R\cup R^{-1}$

**ã€Corollaryã€‘**$R=R\cup R^{-1}$ â‡” $R$ is a symmetric relation

### 3. Transitive closure

* $t(R)$ : the smallest transitive relation containing $R$

**Terminologiesæœ¯è¯­**:

*  <u>***A path of length n in a digraph G***</u> 
  * A sequence of edges $(x_0,x_1),\dots,(x_{n-1},x_n)$
  * Notation: $x_0,x_1,\dots,x_n$
* ***<u>Cycle or circuit</u>*** 
  * If there is a sequence of edges $(x_0,x_1),\dots,(x_{n-1},x_n)$, and $x_0 = x_n$â€‹

 The term path also applies to relation.  

**ã€Theorem1ã€‘** ==Let $R$ be a relation on $A$. There is a path of length $n$ from $a$ to $b$ if and only if $(a,b)\in R^n$==

#### Connectivity Relation

**ã€Definitionã€‘** The ***connectivity relationè”é€šå…³ç³»*** denote by $R^*$, is the set of ordered pairs $(a,b)$ such that there is a path (in $R$) from $a$ to $b$, 

* then is easy to get the equation: $R^*=\cup^{\infty}_{n=1}R^n$

**ã€Theorem2ã€‘** $R$ çš„ä¼ é€’é—­åŒ… $t(R)$ $=$ è¿é€šå…³ç³»$R^*$

* $R=t(R) â‡”\text{R is transitive}$ 
* In fact, we need only consider paths of length $n$ or less.  

**ã€Theoremã€‘** If $|A | = n$, then any <u>path of length > n</u> must contain a cycle. 

**ã€Theoremã€‘**If $|A|=n$, $R$ is a relation on $A$, then $\exist k,k\leq n,R^*=R\cup R^2\cup \dots\cup R^k$

* **ã€Corollaryã€‘** If $|A|=n$, then $t(R)=R^*=R\cup R^2 \cup \dots \cup R^n$
* **ã€Corollaryã€‘** Let $M_R$ be the zero-one matrix of the relation $R$ on a set with $n$ elements. The zero-one matrix of the transitive closure is $M_{t(R)}=M_R \or M_R^{[2]}]  \or \dots\or M_R ^{[n]}$

### 4. Warshall's Algorithm

The interior vertices of a path: $x_0, x_1, x_2, \ldots, x_{n - 1}, x_n$

**Warshall's algorithm** is based on the construction of a sequence of **zero-one matrices**, such as $W_0, W_1, W_2, \ldots, W_n$

*  $ W_0 = M_R $ and $W_k = [w_{ij}^{(k)}] $

$$
w_{ij}^{(k)}= \begin{cases} 1 & \text{If there is a path from } V_i \text{ to } V_j \text{ such that all the interior vertices of this path }\\ &\text{are in the set } \{V_1, V_2, \ldots, V_k\}\\ 0 & \text{otherwise} \end{cases}
$$



*  $ W_n = M_{t(R)} $
*  $ w_{ij}^{(k)}=w_{ij}^{(k - 1)}\vee(w_{ik}^{(k - 1)}\wedge w_{kj}^{(k - 1)})$

## 9.5 Equivalence Relations

### 1. Equivalence Relations

**ã€Definitionã€‘**A relation $R$ on a set $A$ is an ***equivalence relationç­‰ä»·å…³ç³»*** if $R$ is <u>**reflexive, symmetric , transitive**</u>.

* a and b are ***equivalentç›¸å…³*** ($a$~$b$) : $a$ and $b$ are related by an equivalence relation $R$

### 2. Equivalence Classes

* ***the equivalence classç­‰ä»·ç±»*** of $x$:
  The set of all elements that are related to an element $x$ of $A$
* Notation : $[a]_R$,   $[a]_R=\{s âˆ£ (a,s)âˆˆR\}$
* a representative of the equivalence class $[a]_{R}$ : $b\in [a]_R$

### 3. Partition of a Set

**ã€Definitionã€‘**Let be a collection of subsets of $A$. Then the collection forms a ***partitionåˆ†åŒº*** of $A$ if and only if

* $A_i \neq \empty \text{ for }i \in Z$
* $A_i \cap A_j = \empty, when \space i \neq j$
* $\forall a \in A,\exist i\text{ such that }a \in A_i(i=1,2,\dots)$  [ $\cup_{i\in Z}A_i=A$ ]

![image-20250509225218227](image-20250509225218227.png)

> è´å°”æ•° $B_n=\sum_{k=1}^{n}S(n,k)$ , æ»¡è¶³$B_{n+1}=\sum_{k=0}^{n}\binom{n}{k}B_k$,
>
> è´å°”æ•°ä»£è¡¨é›†åˆæœ‰å¤šå°‘ç§åˆ’åˆ†æ–¹å¼ï¼Œä¹Ÿä»£è¡¨é›†åˆå…·æœ‰çš„equivalence relationçš„æ•°é‡

### 4. Equivalence Classes and Partitions

**ã€Theorem 1ã€‘**Let $R$ be an ***equivalence relation*** on a set $A$. The following statements are equivalent :

* $aRb$
* $[a]=[b]$
* $[a]\cap [b]=\empty$

**ã€Theorem 2ã€‘** Let $R$ be an equivalence relation on a set $A$. Then the equivalence classes of $R$ form a partition of $A$. Conversely, given a partition, $\{A_i|i\in I\}$ of the set $A$, there is an equivalence relation $R$ that has the sets $A_i,i\in I$, as its equivalence classes.

### 5. The operations of equivalence relations

**ã€Theorem 3ã€‘** If $R_1,R_2$ are equivalence relations on $A$, then $R_1\cap R_2$ is equivalence relations on $A$.

**ã€Theorem 4ã€‘** If $R_1,R_2$ are equivalence relations on $A$, then $R_1\cup R_2$ is reflexive and symmetric relation on $A$.

**ã€Theorem 5ã€‘** If $R_1,R_2$ are equivalence relations on $A$, then $(R_1\cup R_2)^*$ is an equivalence relation on $A$.

## 9.6 Partial Orderings

### 1. Basic Concepts

* ã€Definitionã€‘Let $R$ be a relation on $S$. Then $R$ is a ***==partial ordering== or partial orderååº*** if $R$ is 
  * **reflexive** 
  * **antisymmetric** - $\forall x \forall y ((x,y)\in R \and (y,x)\in R\rightarrow x=y)$
  * **transitive** 
* Notation : $(S,R)$--- partially ordered set or a ***posetååºé›†***

#### **Comparable/ Incomparable**

**ã€Definitionã€‘**The elements $a$ and $b$ of a poset $(S,âª¯)$ are called ***comparableå¯æ¯”*** if either $aâª¯b$ or $bâª¯a$. When $a$ and $b $ are elements of $S$ such that neither $aâª¯b$ or $bâª¯a$ are called ***incomparableä¸å¯æ¯”***.   

#### **Total order/Linear order**

**ã€Definitionã€‘** If $(S,âª¯)$ is a poset and every two elements of $S$ are comparable, $S$ is called a ***totally  ordered or linearly ordered setå…¨åºé›†***,  $âª¯$ is called a ***==total order== or linear orderå…¨åº***. In this case is called a ***chainé“¾***. 

#### Well-ordered

**ã€Definitionã€‘** $(S, â‰¼)$ is a ***well-ordered setè‰¯åºé›†*** if it is a poset such that $â‰¼$ is a **total ordering** and every nonempty subset of $S$ has **a least element**. 

**ã€Theoremã€‘The principle of well-ordered inductionè‰¯åºå½’çº³æ³•åŸåˆ™** 
Suppose that $S$ is a well-ordered set. 
Then $P(x)$ is true for all $xâˆˆS$ ,if :
For every $yâˆˆS$, if $P(x)$ is true for all $xâˆˆS$ with $x<y$,  then $P(y)$ is true.

### 2. Lexicographic Order

The lexicographic order $â‰¼$ on $A_1\times A_2$

* Given two posets $(A_1,â‰¼_1)$ and $(A_2,â‰¼_2)$, we construct an induced partial order $R$ on $A_1\times A_2$: $(x_1,y_1)â‰¼ (x_2,y_2)$ if $x_1 â‰¼ x_2$ or $x_1=x_2 \and y_1â‰¼ y_2$       

* A lexicographic ordering is a partial ordering defined on a Cartesian product of two posets.

   è¯å…¸åºæ˜¯ä¸¤ä¸ªååºé›†çš„ç¬›å¡å°”ç§¯çš„ååº

* The definition of lexicographic order extends naturally to multiple Cartesian products of partially ordered sets

### 3. Hasse Diagrams 

To construct a ***Hasse diagramå“ˆæ–¯å›¾*** :

1)  ç”»å‡ºååºçš„æœ‰å‘å›¾
2)  å› ä¸ºååºæ˜¯*è‡ªåçš„*ï¼Œæ‰€ä»¥æ¯ä¸ªé¡¶ç‚¹éƒ½ä¼šæœ‰ä¸€ä¸ª***ç¯***$(a,a)$ï¼Œå°†è¿™äº›ç¯å…¨éƒ¨ç§»é™¤
3)  ç”±äºå…¶ä»–è¾¹çš„å­˜åœ¨å’Œä¼ é€’æ€§ï¼Œæˆ‘ä»¬éœ€è¦ç§»é™¤æ‰€æœ‰å¤šä½™çš„è¾¹ï¼Œå³å½“å­˜åœ¨å…ƒç´  $zâˆˆS$ ä½¿å¾— $xâ‰ºz$ ä¸” $zâ‰ºy$æ—¶ï¼Œç§»é™¤è¾¹ $(x,y)$
4)  å¯¹æ‰€æœ‰è¾¹é‡æ–°æ’åºï¼Œä½¿å¾—***èµ·ç‚¹åœ¨ç»ˆç‚¹çš„ä¸‹é¢***ï¼Œå¹¶ä¸”ç§»é™¤æ‰€æœ‰ç®­å¤´ ( å› ä¸ºç°åœ¨æ‰€æœ‰çš„è¾¹éƒ½æ˜¯å‘ä¸ŠæŒ‡çš„ï¼Œæ–¹å‘å·²çŸ¥ )

<img src="images/image-20250603193832040.png" alt="image-20250603193832040" style="zoom:120%;" />

#### Chain and Antichain

ã€Definitionã€‘$(A,â‰¼ )$ is a poset. $B\subset A$, if $(B,â‰¼)$ is a totally ordered set, the $B$ is called a ***chain*** of $(A,â‰¼)$        

ã€Definitionã€‘$(A,â‰¼ )$ is a poset. $B\subset A$, if $\forall a,b \in B(a\neq b),(a,b)\notin R,(b,a)\notin R$, the $B$ is called a ***antichain*** of $(A,â‰¼)$  

* The length of chain: $|B|$, $B$ is a definite set

### 4. Maximal and Minimal Elements

**ã€Definitionã€‘** Let $(A,â‰¼ )$ be a poset. $a\in A$, then $a$ is a ***maximal elementæå¤§å…ƒç´ *** if there does not exist an element $b$ in $A$ such that $aâ‰ºb$. Similarly for a ***minimal elementæå°å…ƒç´ ***. 

**Note**: 

1.  Maximal and minimal elements are the <u>**â€œtopâ€ and â€œbottomâ€**</u> elements in the Hasse diagram. 
2.  There can be <u>**more than one**</u> minimal and maximal element in a poset.

#### Greatest and Least Element 

**ã€Definitionã€‘**Let $(A,â‰¼ )$ be a poset. Then an element $ a$ in $A$ is a ***greatest elementæœ€å¤§å…ƒç´ *** of $A$ if $bâª¯a$ for every $b$ in $A$, and $a$ is a ***least elementæœ€å°å…ƒç´ *** of $A$ if $aâª¯b$ for every $b$ in $ A$.

**ã€Theoremã€‘** The greatest and least element are **unique** when they exist.

#### Upper and Lower Bounds

**ã€Definitionã€‘**Let $A$ be a subset of $S$ in the poset $(S,â‰¼ )$.  If there exists an element $u$ in $S$ such that $aâ‰¼ u$ for all $a$ in $A$, then $u$ is called an ***upper boundä¸Šç•Œ*** of $A$. Similarly for lower bounds.

**ã€Definitionã€‘**If $a$ is an upper bound for $P$ which is less than every other upper bounds then it is the least upper bound, denoted by $lub(S)$. Similarly for the greatest lower bound, denoted by $glb(S)$.

### 5. Lattices 

**ã€Definitionã€‘**A poset is called a ***latticeæ ¼*** if every pair of elements has a $lub$ and a $glb$. 

### 6. Topological Sorting 

We can impose a **total ordering** $â‰¼$ on a poset ***compatibleå…¼å®¹*** with the **partial order** $R$ if $aâ‰¼b$ whenever $aRb$.

> å¯¹äºæŸä¸ªå…¨åº $âª¯$ å’Œååº $R$ï¼Œå¦‚æœå½“ $a R b$ æ—¶ï¼Œ$aâª¯b$ï¼Œåˆ™ç§° $âª¯$ ä¸ $R$ æ˜¯**å…¼å®¹çš„**

* Constructing a compatible total ordering from a partial ordering is called ***topological sortingæ‹“æ‰‘åº***.

**ã€Lemma 1ã€‘**Every finite nonempty poset $(S,  â‰¼)$ has a minimal element

**Algorithm**:  To sort a poset $(S, R)$. 

* Select the **minimal element** $s_1$ form $S$ and put it in the list.
* Select the **minimal element** $s_2$ form $S-\{a_1\}$ and put it in the list.
* Select the **minimal element** $s_3$ form $S-\{a_1,a_2\}$ and put it in the list.
* ......
* Continue until all elements appear in the list  (and $S$ is void).

# Ch10 Graphs
## 10.1 Graphs and Graph Models
### 1. The Concept of Graph
* **ã€Definition 1ã€‘**A ***graphå›¾*** $G=(V,E)$ consists of $V$, a nonempty set of ***verticesé¡¶ç‚¹*** and $E$, a set of ***edges è¾¹***. Each edge has either one or two vertices associated with it, called its ***endpointsç«¯ç‚¹***. An edge is said to connect its endpoints.
  * **Infinite graphæ— é™å›¾**: a graph with an infinite vertex set or an infinite number of edges
  * **Finite graphæœ‰é™å›¾**: a graph with an finite vertex set and a finite number of edges
* **ã€Definition 2ã€‘**A ***directed graphæœ‰å‘å›¾*** (or ***digraph***) $(V, E)$ consists of a nonempty set of vertices $V$ and a set of **directed edges** (or **arcs**) $E$.  
  Each directed edge is associated with an ordered pair of vertices. The directed edge associated with the ordered pair $(u,v)$ is said to start at $u$ and end at $v$.

#### **Types of Graphs**

* **Undirected graphæ— å‘å›¾** : a graph with **undirected** edges. 
  * ***Simple graphç®€å•å›¾*** : A graph in which each edge connects two different vertices and where **no two edges connect the same pair of vertices**. 
  * ***Multigraphå¤šé‡å›¾*** : Graphs that may have **multiple edges** connecting the same vertices.
  * ***Pseudographä¼ªå›¾*** : Graphs that may include **loops**, and possibly multiple edges connecting the same pair of vertices

* **Directed graphæœ‰å‘å›¾** : a graph with **directed** edges. 
  * ***Simple directed graphç®€å•æœ‰å‘å›¾*** : a directed graph has **no loops** and has **no multiple directed edges**.

  * ***Directed multigraphæœ‰å‘å¤šé‡å›¾*** : a directed graphs that may have **multiple directed edges**  from a vertex to a second (possibly the same)  vertex.

* ***Mixed graphæ··åˆå›¾*** : a graph with **both** directed and undirected edges.    

### 2. Graph Models

> Omitted

## 10.2 Graph Terminology and Special Types of Graphs

### 1. Basic Terminology

#### Undirected Graphs

*  Two vertices, u and v in an undirected graph G are called ***adjacentç›¸é‚»*** (or **neighbors**) in $G$, if $\{u, v\}$ is an edge of $G$. 

* An edge $e$ connecting $u$ and $v$ is called ***incident*** with vertices $u$ and $v$, or is said to **connect $u$ and $v$**. 

* The vertices $u$ and $v$ are called **endpoints** of edge $\{u, v\}$. 

* **Loop**: an edge connects a vertex to itself. 

* The **neighborhood** of $v (N(v))$: the set of **all neighbors** of a vertex $v$ 

* The ***degreeåº¦æ•°*** of a vertex in an undirected graph is the number of edges incident with it, except that a loop at a vertex contributes twice to the degree of that vertex     

  Notation: $deg(v)$         

  * If $deg(v) = 0$, $v$ is called **isolatedå­¤ç«‹çš„**.    
  * If $deg(v) = 1$, $v$ is called **pendantä¸‹å‚çš„**.

**ã€Theorem 1ã€‘** ==**The Handshaking Theoremæ¡æ‰‹å®šç†**== : Let $G = (V, E)$ be an undirected graph $G$ with $e$ edges. Then $\sum_{v\in V}deg(v)=2e$

**ã€Theorem 2ã€‘** An undirected graph has an **even number** of vertices of odd degree. åœ¨æ— å‘å›¾ä¸­ï¼Œåº¦ä¸º*å¥‡æ•°*çš„é¡¶ç‚¹ä¸ªæ•°ä¸ºå¶æ•°

#### Directed Graphs 

Let $(u, v)$ be an edge in $G$. Then $u$ is an **initial vertexèµ·ç‚¹** and is adjacent to $v$ and $v$ is a **terminal vertexç»ˆç‚¹** and is adjacent from $u$. The **in degreeå…¥åº¦** of a vertex $v$, denoted $degâ»(v)$, is the number of edges which terminate at $v$. Similarly, the **out degreeå‡ºåº¦** of v, denoted $degâº(v)$, is the number of edges which initiate at $v$. 

**ã€Theorem 3ã€‘**Let $G = (V, E)$ be a graph with direct edges. Then $\sum_{v\in V}d^+(v)=\sum_{v\in V}d^-(v)=|E|$

### 2. Some Special Simple Graphs

* ***Complete Graphså®Œå…¨å›¾*** - ==$K_n$==

  exactly **one edge** between **every pair** of distinct vertices

  <img src="images/image-20250603202522549.png" alt="image-20250603202522549" style="zoom:150%;" />

* ***Cyclesç¯*** - ==$C_n (n>2)$==

  $C_n=(V,E),where \space V=\{v_1,v_2,\dots , v_n\},E=\{(v_1,v_2),(v_2,v_3),\dots , (v_{n-1},v_n),(v_n,v_1)\},n \geq 3$

  <img src="images/image-20250514201741328.png" alt="image-20250514201741328" style="zoom:70%;" />

* ***Wheelsè½®*** - ==$W_n(n>2)$==

  Add one additional vertex to the cycle $C_n$ and add an edge from each vertex to the new vertex to produce $W_n$.

  <img src="images/image-20250514201803199.png" alt="image-20250514201803199" style="zoom:80%;" />

* ***n-Cubes*** - ==$Q_n (n>0)$==

  $$Q_n = \langle V, E \rangle$$ is a graph with $$2^n$$ vertices representing bit strings of length n, where $V = \{ v | v = a_1a_2...a_n, a_i = 0, 1, i = 1, 2, ..., n \}$ and $E = \{ (u, v) | u, v \in V \land u \text{ and } v \text{ differ in exactly one bit position }\}.$

  ![image-20250514103428074](image-20250514103428074.png)

  > * Construct $Q_{n+1}$ from $Q_n$
  >
  >   1. making two copies of $Q_n$ , prefacing the labels on the vertices with a $0$ in one copy and with a $1$ in the other copy  
  >
  >   2. adding edges connecting two vertices that have labels differing only in the first bit 
  >
  >      ![image-20250514103647388](image-20250514103647388.png) 
  >
  > * The number of edges: $a_n=2a_{n-1}+2^{n-1}$

### 3. Bipartite Graphs

* A simple graph $ G $ is ***==bipartiteäºŒåˆ†çš„==*** if $ V $ can be partitioned into two disjoint subsets $ V_1 $ and $ V_2 $ such that every edge connects a vertex in $ V_1 $ and a vertex in $ V_2 $. 

* The pair $ \{V_1, V_2\} $ is called a ***bipartitionäºŒåˆ†*** of the vertex $ V $ of $ G $.

  ![image-20250514104414459](image-20250514104414459.png)

* **ã€Theorem 4ã€‘** A simple graph is **bipartite** if and only if it is possible to assign one of **two different colors** to each vertex of the graph so that no two adjacent vertices are assigned the same color. 

* The **complete bipartite graphå®Œå…¨äºŒåˆ†å›¾** is the simple graph that has its vertex set partitioned into two subsets $ V_1 $ and $ V_2 $ with $ m $ and $ n $ vertices, respectively, and every vertex in $ V_1 $ is connected to every vertex in $ V_2 $, denoted by ==$ K_{m,n} $==, where $ m = |V_1| $ and $ n = |V_2| $.

  ![image-20250514104353981](image-20250514104353981.png)

### 4. Regular graph Regular graph 

* A simply graph is called ==**regular**== if every vertex of this graph has the **same degree**. 
* A regular graph is called **n-regular** if every vertex in this graph has degree $n$

### 5. New Graphs From Old

#### **Subgraph**  

$ G = (V, E) $, $ H = (W, F) $    

* $ H $ is a **subgraphå­å›¾** of $ G $ if $ W\subseteq V$, $F \subseteq E$.     

* subgraph $ H $ is a **proper subgraphçœŸå­å›¾** of $ G $ if $ H \neq G $.    

* $ H $ is a **spanning subgraphç”Ÿæˆå­å›¾** of $G$ if $W = V$, $F \subseteq E$

* **Subgraph inducedç‚¹è¯±å¯¼å­å›¾** by a subset of $V$

   Let $G=(V,E)$ be a simple graph. The subgraph induced by <u>a subset ***W*** of the vertex set ***V***</u> is the graph $(W,F)$, where the edge set $F$ contains an edge in $E$ iff both endpoints of this edge are in $W$

  > å®šä¸€ä¸ªå›¾ $G=(V,E)$ï¼Œå…¶ä¸­ $V$ æ˜¯é¡¶ç‚¹é›†åˆï¼Œ$E$ æ˜¯è¾¹é›†åˆï¼Œå¯¹äº $V$ çš„ä»»æ„éç©ºå­é›† $S$ï¼Œç”± $S$ ä¸­çš„é¡¶ç‚¹ä»¥åŠ $G$ ä¸­è¿æ¥è¿™äº›é¡¶ç‚¹çš„**æ‰€æœ‰è¾¹**ç»„æˆçš„å­å›¾ç§°ä¸º**<u>ç”± S ç‚¹è¯±å¯¼çš„å­å›¾</u>**ã€‚

**å¾—åˆ°æ–°å›¾çš„æ–¹å¼**

  * **Removing edges of a graph** : $G-e=(V,E-\{e\})$
  * **Adding edges to a graph** : $G+e=(V,E+\{e\})$
  * **Edge contration è¾¹å‹ç¼©** : 
    1.  Remove an edge $e$ with endpoints $u$ and $v$, 
    2.  merge $u$ and $v$ into a new single vertex $w$, 
    3.  and for each edge with $u$ or $v$ as an endpoint replaces the edge with one with $w$ as endpoint in place of $u$ and $v$ and with the same second endpoint. 
  * **Removing vertices from a graph** : $G-v =(V-v, Eâ€™)$, where $Eâ€™$ is the set of edges of $G$ not incident to $v$

### 6. Graph Union

The union of two simple graphs $G1 = ( V1 , E1 )$ and $G2 = ( V2 , E2 )$ is the simple graph with vertex set $V = V1 âˆª V2$ and edge set $E = E1 âˆª E2$. 

* Notation:  $G1 âˆª G2$

## 10.3 Representing Graphs and Graph Isomorphism

### 1. Adjacency lists

* lists that specify the vertices that are adjacent to each vertex

  <img src="images/image-20250514204913332.png" alt="image-20250514204913332" style="zoom:80%;" />

### 2. Adjacency Matrices

* A simple graph $G = (V, E)$ with $n$ vertices $(v_1,v_2,\dots,v_n)$ can  be represented by its ***adjacency matrixé‚»æ¥çŸ©é˜µ***, $A$, where $a_{ij} = 1$ if $\{v_i, v_j \}$ is an edge of $G$, $a_{ij} = 0$ otherwise.

  ![image-20250514205654541](image-20250514205654541.png)

* The adjacency matrix of a **multigraph** or **pseudograph**

  The $(i, j)th$ entry of such a matrix equals the number of edges that  are associated to $\{v_i, v_j\}$.

  ![image-20250514210048087](image-20250514210048087.png)

* The adjacency matrix of a **directed graph**

  For directed graph $G = (V, E)$ with $|V| = n$, suppose that the vertices of $G$ are listed in arbitrary order as $v_1, v_2, â€¦, v_n$, the adjacency matrix $A = [a_{ij}]$, where $a_{ij} = 1$ if $(v_i, v_j)$ is an edge of $G$, $a_{ij} = 0$ otherwise.

  ![image-20250514210249748](image-20250514210249748.png)

### 3. Incidence matrices 

$G = (V, E)$, $V = \{v_1, v_2, ..., v_n\}$, $E = \{e_1, e_2, ..., e_m\}$. The ***incidence matrixå…³è”çŸ©é˜µ*** with respect to this ordering of $V$ and $E$ is an $n \times m$ matrix $M = [m_{ij}]_{n \times m}$, where $m_{ij} = \begin{cases} 1 & \text{when edge } e_j \text{ is incident with } v_i \\ 0 & \text{otherwise} \end{cases}$

<img src="images/image-20250514210326735.png" alt="image-20250514210326735" style="zoom:80%;" />

### 4. Isomorphism Of Graphs

* Two simple graphs $ G_1 = (V_1, E_1) $ and $ G_2 = (V_2, E_2) $ are **isomorphicåŒæ„çš„** if there is a $1-1$ and onto function $ f $ ($ f $ is called an **isomorphism**) from $ V_1 $ to $ V_2 $ such that for all $ a $ and $ b $ in $ V_1 $, $ a $ and $ b $ are adjacent in $ G_1 $ iff $ f(a) $ and $ f(b) $ are adjacent in $ G_2 $. 
* In other words, when two simple graphs are isomorphic, there is a **one-to-one correspondence** between vertices of the two graphs that preserves the adjacency relationship.

#### How to determine?

* It is usually difficult to find an isomorphism $f$ since there are $n!$ possible $1-1$ correspondence between the two vertex sets with $n$ vertices.  

* some properties (called **invariantsä¸å˜é‡**) in the graphs may be used to show that they are not **isomorphic**

  **Important invariants in isomorphic graphs**: 

  * the number of vertices 
  * the number of edges 
  * the degrees of corresponding vertices  
  * if one is bipartite, the other must be 
  * if one is complete, the other must be  
  * if one is a wheel, the other must be etc.

## 10.4 Connectivity

### 1. Paths

**The concept of path** : In $G = (V, E)$, it is usually considered that starting from one vertex and terminating at another vertex by passing along some edges. 

#### Definition of path in undirected graph 

* **Path of length $n$ from $u$ to $v$ in an undirected graph**  
* a sequence of $n$ edges $e_1, ..., e_n$ for which there exists a sequence $x_0=u, x_1, ..., x_{n-1}, x_n=v$ such that $e_i$ has endpoints $x_{i-1}$ and $ x_{i}$  
  
* When the graph is simple, we denote this path by its vertex sequence $x_0, x_1, ..., x_{n-1}, x_n$ 
* **Circuit** : if the path begins and ends with the same vertex 
* The path or circuit is said to **pass through** the vertices $x_0, x_1, ..., x_{n-1}, x_n$  or **traverse** the edges $e_1, ..., e_n$ 
* **Simple path/circuit** : if it does not contain the same edge more than once

#### Definition of path in directed graph   

* **path of length $n$ from $u$ to $v$ in a directed graph**  
  * a sequence of edges $e_1, ..., e_n$ such that $e_1$ is associated with $(x_0,x_1),e_2,\dots$
  
  * When there are no multiple edges in the directed graph, this path is denoted by its vertex sequence $x_0, x_1, ..., x_{n-1}, x_n$ 
  
* **circuit or cycle**  
  * if the path begins and ends with the same vertex 

* **simple path/circuit**  
  * if it does not contain the same edge more than once

### 2. Connectedness in undirected graphs

**Definition**

* An undirected graph is **connectedè”é€šçš„** : if there is a path between **every pair** of distinct vertices 
* An undirected graph is **disconnectedä¸è¿é€šçš„** : the graph is not connected 
* **Disconnect** a graph: remove vertices or edges, or both, to produce a disconnected subgraph. 

**ã€Theorem 1ã€‘**There is a simple path between every pair of distinct vertices of a connected undirected graph. 

**Connected Componentsè¿é€šåˆ†é‡** : The maximally connected subgraphs of $G$ are called the **connected components** or just the **components**. 

### 3. How connected is a graph?

* **cut vertexå‰²ç‚¹** (or articulation point) 
  * if removing a vertex and all edges incident with it results in **more connected components** than in the original graph. 
* **cut edgeå‰²è¾¹** or bridge 
  * if removing a edge creates **more components**
* **nonseparable graphsä¸å¯åˆ†å‰²å›¾**
  * Connected graphs without cut vertices
  * Nonseparable graphs can be thought of as more connected than those with a cut vertex.

### 4. Vertex connectivity

>  How to measure graph connectivity?
>
> * based on the minimum number of vertices that can be removed to disconnect a graph

**Vertex cut, or separating set ç‚¹å‰²é›†**: a subset $Vâ€™$ of the vertex set $V$ of $G=(V,E)$ such that $G-Vâ€™$ is disconnected.

* Every connected graph except a complete graph has a vertex cut.

**Vertex connectivityç‚¹è¿é€šåº¦** $Îº(G)$ : the minimum number of vertices in a vertex cut. 

* $0\leq Îº(G) \leq n-1$

* $ Îº(G) =0$ iff $G$ is disconnected or $G=K_1$

* $ Îº(G) =1$ iff $G$ is connected with cut vertices or $G=K_2$

* $ Îº(G) =n-1$ iff $G$ is complete

  > $K_n$ denotes a complete graph which has $n$ nodes

A graph is **K-connected** (or k-vertex-connected ), if $Îº(G)â‰¥K$

### 5. Edge connectivity

**edge cutè¾¹å‰²é›†**: a set of edges $Eâ€™$  is called an edge cut of $G$ if the subgraph $G-Eâ€™$ is disconnected.

**edge connectivityè¾¹è¿é€šåº¦** $Î»(G)$ : the minimum number of edges in an edge cut of $G$.

* $0\leq Î»(G) \leq n-1$ if $G$ has $n$ vertices
* $Î»(G)=0$ if $G$ is disconnected or $G$ is a graph consisting of a single vertice
* $Î»(G)=n-1$ iff $G=K_n$

**å…³äºç‚¹è¿é€šåº¦å’Œè¾¹è¿é€šåº¦çš„ä¸ç­‰å¼**

* When $G=(V,E)$ is a noncomplete connected graph with at least three vertices $Îº(G)â‰¤Î»(G)â‰¤min_{v \in V}deg(v)$

### 6. Connectedness in directed graphs

* **strongly connected** 
  * if there is a path from $a$ to $b$ and from $b$ to $a$ for **all** vertices $a$ and $b$ in the graph.   

* **weakly connected** 
  * if the underlying undirected graph is connected
* **strong components of a directed graph**
  * For directed graph, the maximal strongly connected subgraphs are called **the strongly connected componentså¼ºè¿é€šåˆ†é‡** or just **the strong components**

> A weakly connected directed graph with $deg^+(v)=deg^-(v)$ for all vertices $v$ is strongly connected.

### 7. Paths and Isomorphism

* Some other graph invariants involving path  
  * Two graphs are **isomorphic** only if they have <u>simple circuits of the same length</u>.  
  * Two graphs are **isomorphic** only if they contain paths that go through vertices so that the corresponding vertices in the two graphs have the same degree.  

* We can also use paths to find mapping that are potential isomorphisms

### 8. Counting paths between vertices 

**ã€ Theorem 2ã€‘** The number of different paths of length $r$ from $v_i$ to $v_j$ is equal to the $(i, j)th$ entry of $A^r$, where $A$ is the adjacency matrix representing the graph consisting of vertices $v_1, v_2, . . . v_n$.

## 10.5 Euler and Hamilton Paths

### 1. Euler Paths and Circuits

* ==**Euler Path æ¬§æ‹‰è·¯**==: a simple path containing every edge of $G$ 
* ==**Euler Circuit æ¬§æ‹‰ç¯**==: a simple circuit containing every edge of $G$ 
* ==**Euler Graph æ¬§æ‹‰å›¾**==: A graph contains an Euler circuit

**ã€Theorem 1ã€‘** A connected multigraph has an Euler circuit if and only if each of its vertices has ==**even** degree==.

**ã€Theorem 2ã€‘** A connected multigraph has an Euler path but not an Euler circuit if and only if it has ==exactly **two** vertices of odd degree==.

#### Euler circuits and paths in directed graphs

 A directed multigraph having no isolated vertices has an **Euler circuit** if and only if 

* the graph is **weakly connected** 
* the <u>in-degree and out-degree</u> of each vertex are **equal**.

A directed multigraph having no isolated vertices has an **Euler path** but not an Euler circuit if and only if 

* the graph is **weakly connected** 
* the <u>in-degree and out-degree</u> of each vertex are **equal** for all but two vertices, one that has in-degree $1$ larger than its out degree and the other that has out-degree $1$ larger than its in-degree.

### 2. Hamiltonâ€™s paths and Circuits

* ==**Hamilton path å“ˆå¯†é¡¿è·¯**==: a path which visits every vertex in $G$ **exactly once** 
* ==**Hamilton circuit å“ˆå¯†é¡¿ç¯ (or Hamilton cycle)**==: a cycle which visits every vertex **exactly once**, except for the first vertex, which is also visited at the end of the cycle. 
* ==**Hamilton graph å“ˆå¯†é¡¿å›¾**==: a connected graph $G$ has a Hamilton circuit

**ã€ Theorem 3ã€‘** ==**DIRAC' THEOREM ç‹„æ‹‰å…‹å®šç†**==: If $G$ is a <u>simple graph</u> with $n$ vertices $n \geq 3$ such that the degree of every vertex in $G$ is at least $n/2$, then $G$ has a Hamilton circuit.  

**ã€ Theorem 4ã€‘** ==**ORE' THEOREM å¥¥å°”å®šç†**==: If $G$ is a simple graph with $n$ vertices with $n\geq3$ such that $deg(u)+deg(v) \geq n$ for every pair of **nonadjacent vertices** $u$ and $v$ in $G$, then $G$ has a Hamilton circuit.

**Another important necessary condition**:

* For any nonempty subset $S$ of set $V$, the number of connected components in $G-S$ $\leq|S|$

## 10.6 Shortest Path Problems

* Weighted graph å¸¦æƒå›¾:  $G = (V,E,W)$ 
* the length of a path in a weighted graph: The **sum** of the weights of the edges of this path

### A Shortest path Algorithm

$G=(V,E,W)$ is a weighted graph, where $w(x,y)$ is the weight of edge associated vertices $x$ and $y$  (if $(x,y)\notin E,w(x,y)=\infty$ ), $a,z\in V$ , find the shortest path between $a$ and $z$.

#### **Dijkstraâ€™s Algorithm**

 Let $S_k$ denote the set of vertices after $k$ iterations of **labeling procedure**. 

1.  Initialization. Label $a$ with $0$ and other with $âˆ$, i.e. $L_0(a)=0$, and $L_0(v)= âˆ$ and $S_0=Ï†$
2.  Form $S_k$. The set $S_k$ is formed from $S_{k-1}$ by adding a vertex $u$ not in $S_{k-1}$ with the smallest label.  
3.  Update the labels of all vertices not in $S_k$ , so that $L_k(v)$, the label of the vertex $v$ at the $k_{th}$ stage, is the length of the shortest path from $a$ to $v$ that containing vertices only in $S_k$
4.  Step $2$ and $3$ is iterated by successively adding vertices to the distinguished set the until $z$ is added.

* Update the labels of all vertices not in $S_k$ : $L_k(v)=min\{L_{k-1}(v), L_{k-1}(u)+w(u,v)\}$

**ã€Theorem 1ã€‘**Dijkstraâ€™s algorithm finds the length of a shortest path between two vertices in a connected simple undirected weighted graph.

**ã€Theorem 2ã€‘**Dijkstraâ€™s algorithm uses $O(n^2 )$ operations (additions and comparisons) to find the length of the shortest path between two vertices in a connected simple undirected weighted graph.

#### The Traveling Salesperson Problem

**Solving TSP**

The most straightforward one:  

* Examine all possible Hamilton circuits and select one of  minimum total length. How many are there different length of Hamilton circuits in a complete graph with n vertices?
* $(n-1)!/2$

Approximation algorithm:

* do not necessary produce the exact solution 
* to produce a solution that is close to an exact solution

## 10.7 Planar Graphs

ã€Definitionã€‘A graph is called **planarå¹³é¢çš„** if it can be drawn in the plane without any edges crossing. 

* Such a drawing is called a **planar representationå¹³é¢è¡¨ç¤ºæ³•** of the graph.

### 1. Some terminologies: 

* **Region**: a part of the plane completely disconnected off from other parts of the plane by the edges of the graph. 

  * Bounded region  
  * Unbounded region 

  Note: There is **one unbounded region** in a planar graph. 

* **the boundary of region** 

* **the Degree of Region** $R$ ($Deg(R)$): the number of the edges which surround $R$, suppose $R$ is a region of a connected planar simple graph 

* **adjacent regions**: two regions with a common border  

* If $e$ is not a cut edge, then it must be the **common border** of two regions

### 2. Eulerâ€™s Formula

#### **ã€Theorem 1ã€‘** **==Eulerâ€™s formula==** 

* Let $G$ be a **connected planar simple graph** with $e$ edges and $v$ vertices. Let $r$ be the number of regions in a planar representation of $G$. Then ==$r=e-v+2$==.

* For **Unconnected simple planar graph**: Suppose that a planar graph $G$ has $k$ connected components, $e$ edges, and $v$ vertices. Let $r$ be the number of regions in a planar representation of $G$. Then ==$r=e-v+k+1$==.

**ã€Corollary 1ã€‘**If $G$ is a **connected** planar simple graph with $e$ edges and $v$ vertices where $vâ‰¥3$, then $eâ‰¤3v-6$. 

> æ˜¾ç„¶ $deg(R) â‰¥ 3$, å¹¶ä¸” $2e=\sum_{all \space regions \space R}degR \geq 3r$, ç»“åˆæ¬§æ‹‰å…¬å¼å¯è¯æ˜

**ã€Corollary 2ã€‘**If a **connected** planar simple graph has $e$ edges and $v$ vertices with $vâ‰¥3$ and no circuits of length $3$, then $e â‰¤2v-4$.

> æ˜¾ç„¶ $deg(R) â‰¥ 4$, å¹¶ä¸” $2e=\sum_{all \space regions \space R}degR \geq 4r$, ç»“åˆæ¬§æ‹‰å…¬å¼å¯è¯æ˜

**ã€Corollary 3ã€‘**If $G$ is a **connected** planar simple graph, then $G$ has a vertex of degree not exceeding **five**.

> By Corollary 1 , we know that $eâ‰¤3v-6$ , so $2eâ‰¤6v-12$. If the degree of every vertex were at least six, then $2eâ‰¥6v$, there is no solution

### 3. Kuratowski's Theorem

**Elementary subdivisionåˆç­‰ç»†åˆ†**: If a graph is planar, so will be any graph obtained by removing an edge $\{u, v\}$ and adding a new vertex $w$ together with edges $\{u,w\}$ and $\{w,v\}$.

![image-20250523222110861](image-20250523222110861.png)

**homeomorphicåŒèƒšçš„** : the graph $G_1=(V_1,E_1)$ and $G_2=(V_2,E_2)$ are called **homeomorphic** if they can be obtained from the same graph by a sequence of elementary subdivision.

**ã€Theorem 2ã€‘** ==A graph is nonplanar if and only if it contains a subgraph **homeomorphic** to $K_{3,3}\space or\space K_5$.==

## 10.8 Graph Coloring

the **dual graphå¯¹å¶å›¾** of the map 

* Each region of the map is represented by a vertex.  
* Edge connect two vertices if the regions represented by these vertices have a common border.  
* Two regions that touch at only one point are not considered  adjacent.

![image-20250531161419396](image-20250531161419396.png)

### The chromatic numbers of a graph

Terminologies: 

* **Coloring**: the assignment of a color to each vertex of the graph so that no two adjacent vertices  are assigned the same color. 
* **chromatic number $Ï‡(G)$**: the least number of colors needed for a coloring of this graph

**The chromatic numbers of some simple graphs**

1. The graph $G$ contains only some isolated vertices. $Ï‡(G)=1$

2. The graph $G$ is a path containing no circuit. $Ï‡(G)=2$

3. $C_n(n \geq 3)$ , $$\begin{cases} \chi(C_n) = 2 & \text{if } n \text{ is even} \\ \chi(G) = 3 & \text{if } n \text{ is odd} \end{cases}$$

   

   <img src="images/image-20250531162954522.png" alt="image-20250531162954522"  />

4. $K_n$

   $Ï‡(K_n)=n$  $Ï‡(K_n-e)=n-1$ <img src="images/image-20250531162921690.png" alt="image-20250531162921690" style="zoom:50%;" />

5. $K_{m,n}$

   $Ï‡(K_{m,n})=2$ <img src="images/image-20250531162939223.png" alt="image-20250531162939223" style="zoom:50%;" />

### Algorithm for coloring simple graphs

![image-20250531163157862](image-20250531163157862.png)

**ã€ Theorem 1ã€‘** **==The Four Color Theorem==** 
The chromatic number of a **planar graph** is **no greater than four**.

# Ch11 Trees

## 11.1 Introduction to Trees

### 1. Tree

**ã€Definitionã€‘**: A tree is a **<u>connected undirected</u>** graph with **<u>no simple circuits</u>**.

* **Note**: Any tree must be a simple graph. 

**ã€Definitionã€‘**:  A **forest** is a graph that has no simple circuit, but is not connected. Each of the connected components in a forest is a tree. 

**ã€Theorem 1ã€‘**: An undirected graph is a tree if and only if there is a **unique simple** path between any two of its vertices.

#### Root tree

**ã€Definitionã€‘**: A **rooted treeæœ‰æ ¹æ ‘** is a tree in which one vertex has been designated as the root and every edge is directed away from the  root.

**ã€Definitionã€‘**: A rooted tree is called a **m-ary tree må‰æ ‘** if every internal vertex has **no more than** $m$ children. 

**ã€Definitionã€‘**: A rooted tree is called a **full m-ary tree æ»¡må‰æ ‘** if every internal vertex has **exactly** $m$ children. 

**ã€Definitionã€‘**: An **ordered rooted tree** is a rooted tree where the children of each internal vertex are ordered.

* In an ordered binary tree, the two possible children of a vertex are called the **left child** and the **right child**, if they exist. 
* The tree rooted at the left child is called the **left subtree**, and that rooted at the right child is called the **right subtree**.

#### Rooted Tree Terminology

* **Parent & Child**

  The parent of a non-root vertex $v$ is the unique vertex $u$ with a directed edge from $u$ to $v$.

* **Sibling**

  Vertices with the same parent are called **siblings**.

* **Ancestors & Descendants** 

  * The **ancestors of a non-root vertex** are all the vertices in the path from root to this vertex.   
  * The **descendants of vertex $v$** are all the vertices that have $v$ as an ancestor.  

* **Leaf**

  A vertex is called a **leaf** if it has no children.

* **Internal Vertex** 

  A vertex that have children is called an **internal vertex**.

* **Subtree** 

  The **subtree** at vertex $v$ is the subgraph of the tree consisting of vertex $v$ and its descendants and all edges incident to those descendants. 

### 2. Properties of Trees

**ã€Theorem 2ã€‘** A tree with $n$ vertices has $n-1$ edges.

**ã€Theorem 3ã€‘** A full $m-ary$ tree with $i$ internal vertices contains $n=mi+1$ vertices.

**ã€Theorem 4ã€‘** A full $m-ary$ tree with 

* $n$ vertices has $i=\frac{n-1}{m}$ internal vertices and $l=\frac{(m-1)n+1}{m}$  leaves 
* $i$ internal vertices has $n=mi+1$ vertices and $l=(m-1)i+1$ leaves  
* $l$ leaves has $n=\frac{ml-1}{m-1}$ vertices and $i=\frac{l-1}{m-1}$ internal vertices

The **levelå±‚çº§** of vertex $v$ in a rooted tree is the **length** of the unique path <u>from the root to $v$</u>.     

The **heighté«˜åº¦** of a rooted tree is the <u>maximum of the levels</u> of its vertices. ($\text{the height of root}=0$)

* A rooted $m-ary$ tree of height $h$ is called **balancedå¹³è¡¡çš„** if all its leaves are at levels $h$ or $h-1$.

**ã€Theorem 5ã€‘**There are at most $m^h$ leaves in an $m-ary$ tree of height $h$.

**ã€Corallaryã€‘**

* If an $m-ary$ tree of height $h $ has $l$ leaves, then $h â‰¥ âŒˆ log_m l âŒ‰$.
* If the $m-ary$ tree is **full and balanced**, then $h = âŒˆ log_m l âŒ‰$.

## 11.2 Applications of Trees

### 1. Binary Search Trees

* A binary search tree can be used to **store item**s in its vertices. It enables efficient searches.
* **Binary search tree**  
  * An ordered rooted binary tree 
  * Each vertex contains a distinct **key value** 
  * The key values in the tree can be compared using â€œgreater thanâ€ and â€œless thanâ€, and
  * The key value of each vertex in the tree is **less than every key value in its right subtree**, and **greater than every key value in its left subtree**.

<img src="images/image-20250531202859165.png" alt="image-20250531202859165" style="zoom:67%;" />

### 2. Decision Trees 

* Rooted trees can be used to model problems in which a series of decisions leads to a solution.  
* A rooted tree in which each internal vertex corresponds to a decision, with a subtree at these vertices for each possible outcome of the decision, is called a **decision treeå†³ç­–æ ‘**.

<img src="images/image-20250531203145819.png" alt="image-20250531203145819" style="zoom:60%;" />

### 3. Prefix Codes

* To ensure that no bit string corresponds to more than one sequence  of letters, the bit string for a letter must never occur as the first  part of the bit string for another letter. Codes with this property are called **prefix codeså‰ç¼€ç **.

#### Huffman Coding

<img src="images/image-20250601104000549.png" alt="image-20250601104000549" style="zoom:80%;" />

* **Huffman Tree å“ˆå¤«æ›¼æ ‘**

  > æµç¨‹ï¼š
  >
  > - åˆå§‹çŠ¶æ€ä¸‹ï¼Œæœ‰ä¸€ç‰‡æ£®æ—ï¼Œå…¶ä¸­æ¯æ£µæ ‘åªæœ‰ä¸€ä¸ªè¡¨ç¤ºä¸åŒå­—ç¬¦çš„èŠ‚ç‚¹
  >
  > - æ¯ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬æŒ‘é€‰æƒé‡ ( é¢‘ç‡ ) æœ€å°çš„ä¸¤æ£µæ ‘ï¼Œç»„æˆæ–°çš„æ ‘ï¼š
  >
  >   - å¼•å…¥ä¸€ä¸ªæ–°çš„æ ¹
  >   - å°†**æƒé‡è¾ƒå¤§**çš„æ ‘ä½œä¸º**å·¦å­æ ‘**
  >   - å°†æƒé‡è¾ƒå°çš„æ ‘ä½œä¸º**å³å­æ ‘**
  >   - æ–°çš„æ ‘çš„æƒé‡ä¸º 2 æ£µæ ‘çš„æƒé‡å’Œ
  >
  >   ç„¶åå°†æ–°çš„æ ‘æ”¾å›åŸæ¥çš„æ£®æ—ä¸­
  >
  > - ç›´åˆ°åªå‰©ä¸‹ä¸€æ£µæ ‘æ—¶ä¸ºæ­¢

![image-20250603214511014](image-20250603214511014.png)

## 11.3 Tree Traversal

* A traversal algorithm is a procedure for **systematically visiting every vertex** of an ordered rooted tree.   
* Tree traversals are defined recursively.  

### 1. Preorder Traversal

```pseudocode
procedure  preorder (T: ordered rooted tree)
r := root of T
list r
for each child c of r from left to 
right
 T(c) := subtree with c as root
 preorder(T(c))
```

### 2. Inorder Traversal

```pseudocode
procedure  inorder (T: ordered rooted tree)
r := root of T
if r is a leaf then list r
else
    l := first child of r from left to right
    T(l) := subtree with l as its root
    inorder(T(l))
    list(r)
    for each child c of r from left to right
       T(c) := subtree with c as root
       inorder(T(c))
```

### 3. Postorder Traversal

```pseudocode
procedure  postordered (T: ordered rooted tree)
r := root of T
for each child c of r from left to right
   T(c) := subtree with c as root
   postorder(T(c))
list r
```

### Expression Trees

A Binary Expression Tree is a special kind of binary tree in which: 

* Each **leaf node** contains a single operand, 
* Each **nonleaf node** contains a single operator, and 
* The left and right subtrees of an operator node represent **subexpressions** that must be evaluated **before** applying the operator at the root of the subtree.

<img src="images/image-20250601105129898.png" alt="image-20250601105129898" style="zoom:80%;" />

* **Infix Formä¸­ç¼€å¼**: An **inorder traversal** of the tree representing an expression produces the original expression when parentheses are included except for unary operations, which now immediately follow their operands. 
  * infix form: $3*ln(x+1)+a/x \uparrow 2$
* **Prefix Formå‰ç¼€å¼**: The expression obtained by an preorder traversal of the binary tree is said to be in prefix form ( **Polish notationæ³¢å…°è¡¨ç¤ºæ³•** ).
  * prefix form: $+*3ln+x1/a\uparrow x2$
* **Postfix Formåç¼€å¼**: The expression obtained by an postorder traversal of the binary tree is said to be in postfix form ( **reverse Polish notationé€†æ³¢å…°è¡¨ç¤ºæ³•** ).
  * postfix form: $3x1+ln*ax2\uparrow /+$

## 11.4 Spanning Trees 

ã€Definition1ã€‘Let $G$ be a simple graph. A **spanning treeç”Ÿæˆæ ‘** of $G$ is a subgraph of $G$ that is **a tree containing every vertex of $G$**.

ã€Theorem 1ã€‘A simple graph is connected if and only if it has a spanning tree.

### Depth-first search

* **Depth-first searchæ·±åº¦ä¼˜å…ˆç®—æ³•** (also called **backtrackingå›æº¯**) -- this procedure forms a rooted tree, and the underlying undirected graph is a spanning tree. 

1.  å…ˆåœ¨å›¾ä¸­ä»»æ„é€‰å–ä¸€ä¸ªé¡¶ç‚¹ä½œä¸ºæ ¹èŠ‚ç‚¹
2.  ä»æ ¹èŠ‚ç‚¹å‡ºå‘ï¼Œè¿ç»­æ·»åŠ é¡¶ç‚¹å’Œè¾¹ï¼Œå…¶ä¸­æ–°å¢çš„è¾¹ä¸€å®šä¸æœ€åæ·»åŠ çš„é¡¶ç‚¹ç›¸å…³è”ï¼Œä¸”æ–°æ·»çš„é¡¶ç‚¹å°šä¸åœ¨è·¯å¾„ä¸­ï¼Œå°½å¯èƒ½åœ°å¾€ä¸‹è¿™æ ·åš
3.  å½“è®¿é—®å®Œæ‰€æœ‰é¡¶ç‚¹æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€æ£µç”Ÿæˆæ ‘
4.  å¦åˆ™ ( é‡åˆ°â€œæ­»èƒ¡åŒâ€)ï¼Œè¿”å›åˆ°è·¯å¾„ä¸­å€’æ•°ç¬¬äºŒä¸ªé¡¶ç‚¹ï¼Œè‹¥æœ‰å¯èƒ½ï¼Œä»è¯¥é¡¶ç‚¹å‡ºå‘ï¼ŒæŒ‰ç…§ä¸Šé¢çš„æ­¥éª¤é‡æ–°å¯»æ‰¾æ–°çš„è·¯å¾„ ( è¦æ‰¾æœªè¢«è®¿é—®è¿‡çš„é¡¶ç‚¹ )ã€‚å¦‚æœæ‰¾å®Œæ‰€æœ‰å¯èƒ½ï¼Œå†è¿”å›ä¸Šä¸€ä¸ªé¡¶ç‚¹ï¼Œå†å¯»æ‰¾æ–°çš„è·¯å¾„ï¼Œç›´è‡³æ‰€æœ‰é¡¶ç‚¹å‡è¢«è®¿é—®è¿‡

```pseudocode
procedure DFS(G: connected graph with vertices v1, v2, â€¦, vn)
T := tree consisting only of the vertex v1   
visit(v1)

procedure visit(v: vertex of G)
for each vertex w adjacent to v and not yet in T
  add vertex w and edge {v,w} to T
  visit(w)
```

### Breadth-first search

* **Breadth-first searchå®½åº¦ä¼˜å…ˆç®—æ³•**

1.  å…ˆåœ¨å›¾ä¸­ä»»æ„é€‰å–ä¸€ä¸ªé¡¶ç‚¹ä½œä¸ºæ ¹èŠ‚ç‚¹
2.  å°†æ‰€æœ‰ä¸æ ¹èŠ‚ç‚¹ç›¸é‚»çš„é¡¶ç‚¹æ·»åŠ è‡³æ ‘å†…ï¼Œå¯¹å®ƒä»¬ä»»æ„æ’åºï¼Œè¿™äº›é¡¶ç‚¹å› è€Œæˆä¸ºç”Ÿæˆæ ‘ä¸­å±‚çº§ä¸º 1 çš„èŠ‚ç‚¹ï¼Œ
3.  å¯¹äºå±‚çº§ä¸º 1 çš„æ‰€æœ‰èŠ‚ç‚¹ï¼ŒæŒ‰é¡ºåºä¾æ¬¡è®¿é—®æ‰€æœ‰ä¸è¿™äº›é¡¶ç‚¹å…³è”çš„è¾¹ä¸Šçš„å¦ä¸€ä¸ªé¡¶ç‚¹ï¼Œä¸”ä¿è¯ä¸ä¼šäº§ç”Ÿç®€å•ç¯ï¼Œå¯¹å¾—åˆ°çš„é¡¶ç‚¹è¿›è¡Œä»»æ„æ’åº
4.  è¿™æ ·ï¼Œæˆ‘ä»¬å¾—åˆ°å±‚çº§ä¸º 1 çš„èŠ‚ç‚¹çš„æ‰€æœ‰å­©å­ï¼Œå®ƒä»¬æ„æˆå±‚çº§ä¸º 2 çš„èŠ‚ç‚¹
5.  å¦‚æ­¤å¾€å¤ï¼Œç›´è‡³æ‰€æœ‰é¡¶ç‚¹è¢«æ·»åŠ è‡³æ ‘å†…

```pseudocode
procedure BFS(G: connected graph with vertices v1, v2, â€¦, vn)
T := tree consisting only of the vertex v1   
L := empty list visit(v1)
put v1 in the list L of unprocessed vertices
while L is not empty
  remove the first vertex, v, from L
  for each neighbor w of v 
    if w is not in L and not in T then
       add w to the end of the list L
       add w and edge {v,w} to T
```

### Backtracking scheme

![image-20250604104545179](image-20250604104545179.png)

## 11.5 Minimum Spanning Trees

ã€Definition1ã€‘A minimum spanning tree in a connected weighted graph is a spanning tree that has the smallest possible sum of weights of its edges.

### Prim's algorithm

* æ€æƒ³ï¼šåœ¨å›¾ä¸­å‰©ä½™çš„è¾¹é‡Œï¼Œå°†ä¸æ ‘ä¸­èŠ‚ç‚¹æœ‰å…³è”çš„æƒé‡æœ€å°çš„è¾¹åŠ åˆ°æ ‘ä¸­

```pseudocode
Procedure Prim (G: weighted connected undirected graph with n vertices)
T:= a minimum-weight edge
for i:= 1 to n-2
begin
  e:= an edge of minimum weight incident to a vertex in   
      T and not forming a simple circuit in T if added to T.
  T:= T with e added
end {T is a minimum spanning tree of G}
```

### Kruskal's algorithm

* æŒ‘é€‰å½“å‰å›¾ä¸­å‰©ä½™çš„è¾¹é‡Œæƒé‡æœ€å°çš„è¾¹ï¼Œä¸”ä¸ä¼šäº§ç”Ÿç¯

```pseudocode
procedure Kruskal (G: weighted connected undirected graph with n vertices)
T:= empty graph
for i:= 1 to n-1
begin
  e:= any edge in G with smallest weight that does not 
      form a simple circuit when added to T
  T:= T with e added
end {T is a minimum spanning tree of G}
```

